{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30530,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/narberalgamma/mnist-classification-neural-network-from-scratch?scriptVersionId=208395367\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"---\n## Title: MNIST Classification-Neural Network from Scratch\n## Author: Edgar M.\n## Date: 10/11/23\n---","metadata":{}},{"cell_type":"markdown","source":"## Introduction\nThe purpose of this notebook is to build a feedforward classification<br> \nneural networks from scratch. What does from scratch mean? It means<br>\nthat I will not be using any machine learning libraries (e.g. keras,<br>\ntensorflow, pytorch, etc.). I will only be using the R libraries that<br>\nare pasted below. Neural network is made up of input layer, either one or<br>\ntwo hidden layers, and output layer. Feedforward neural network is for<br> \nMNIST data classification. The first type of neural network is one with<br> \nno mappings. Continuing the derivation. The second type of neural network<br> \nis with Fourier feature mapping. Idea for Fourier feature mapping came<br> \nfrom the paper, “Fourier Features Let Networks Learn High Frequency<br> \nFunctions in Low Dimensional Domains.\" As I progress through this<br> \nnotebook. I will expand on the idea of neural network with no mapping and<br> \nneural networks with Fourier feature mapping.<br>\n\nMy original plan was to include all the derived math within this notebook.<br>\nBut my full derivation was more than 20 pages long, hence I will only<br>\ninclude the most important parts from my derivation. My Derivation is<br>\nlonger than other standard derivation lenghts that I've seen, because it<br> \nis my first classification neural network from scratch and I did not skip<br> \nover most of the trivial easy to see stuff. Mostly for my own sanity. As<br> \nlater in the future. I want to come back and find it very easy to see<br> \nwhat I did, without breaking my brain. Basic math topics reader should<br> \nbe familiar with are matrix algebra and multivariable calculus. With all<br> \nthat being said. Let’s begin :)<br>\n\nLoad necessary libraries and data.<br>","metadata":{}},{"cell_type":"code","source":"#load nessary libraries\n#suppressMessages() is used to suppress messages from being printed in console\nlibrary(magrittr)\nlibrary(dplyr) %>% suppressMessages()\nlibrary(readr) \nlibrary(ggplot2)  \n\n#Load data\nData <-read_csv(\"/kaggle/input/digit-recognizer/train.csv\") %>% suppressMessages()\n\n#Convert Data into a matrix\nData <-as.matrix(Data) ","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:24:46.037002Z","iopub.execute_input":"2024-02-28T14:24:46.104205Z","iopub.status.idle":"2024-02-28T14:24:56.788976Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Parameter Setup and Data Preparation for Image Classification\n### Image Matrix\nCounting the zeroth pixel as one and the 783th pixel as 784, then there's<br>\n784 pixels in total. Each pixel is a number between 0 and 255, which<br>\nrepresents the intensity of the pixel. \"0 means background (white), 255\"<br>\n\"means foreground (black)\" (Yann LeCun, Corinna Cortes, Christopher J.C.<br>\nBurges, 1998).<br>\n\nAccording to THE MNIST DATABASE of handwritten digits. Each 0 to 9 digit<br>\nis from a 28 by 28 image matrix.<br>\n\n\\begin{equation} \\text{Image Matrix}\\ = \\begin{bmatrix}\npixel0 & pixel1 & pixel2 &...pixel27 \\\\\npixel28 & pixel29 & pixel30 &...pixel55\\\\\npixel56 & pixel57 & pixel58 &...pixel83\\\\\n. & . & . & .\\\\\n. & . & . & .\\\\\n. & . & . & .\\\\\npixel756 & pixel757 & pixel758 &...pixel783\\\\\n\\end{bmatrix} \\end{equation}\n\nYou can mathematically convert an image matrix into a row vector by:<br>\n\n\\begin{equation} Row Image Vector = [Vec((\\text{Image Matrix})^T)]^T \\end{equation}\n\n\\begin{equation} Row Image Vector = \\begin{bmatrix}\npixel0 & pixel1 & pixel2 & pixel3 & ...pixel783 \\\\\n\\end{bmatrix} \\end{equation}\n\nThe first 5 columns and first 5 rows of the training data are shown below.","metadata":{"_kg_hide-input":false}},{"cell_type":"code","source":"head(Data[, 1:5], n = 5)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:25:03.322003Z","iopub.execute_input":"2024-02-28T14:25:03.32388Z","iopub.status.idle":"2024-02-28T14:25:03.355746Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The last 5 columns and first 5 rows of the training data are shown below.","metadata":{}},{"cell_type":"code","source":"col_4 <-ncol(Data) - 4\nhead(Data[, col_4:ncol(Data)], n = 5)","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2024-02-28T14:25:06.216923Z","iopub.execute_input":"2024-02-28T14:25:06.218661Z","iopub.status.idle":"2024-02-28T14:25:06.245171Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Each row of the MNIST dataset is as follows:<br>\n\\begin{equation}\\begin{bmatrix}\nlabel & pixel0 & pixel1 & pixel2 & pixel3 & ...pixel783 \\\\\n\\end{bmatrix}\\end{equation}\n\nLabel column is the **y** dependent variable, and pixels are the **x**<br>\nindependent variables. For each row we have:<br>\n\n\\begin{equation}\\begin{bmatrix}\n[y] & [Row Image Vector] \\\\\n\\end{bmatrix}\\end{equation}\n\n### Parameter Configuration and Data Splitting for Training and Testing\n\nLet Q = number of classification categories, which in this case Q = 10.<br>\n\nLet N = Total number of observations, which in this case N = 42000.<br>\n\\begin{equation}\nN = N_{training} + N_{testing}\\ = training + testing\\end{equation}\nGood rule of thumb for the total number of observations for training-testing<br> \ncan be set as (%80-%20), (%90-%10) or some other percentage.<br>  \n\n\\begin{equation}N_{training} =N*percent\\end{equation}\nTotal number of observations for testing.<br>\n\\begin{equation}N_{testing} =N-N_{training}\\end{equation}\n\nLet: <br>\n\\begin{equation} n\\in N_{training} \\end{equation}\nStochastic gradient descent (1 observation)<br>\n\\begin{equation}n = 1 \\end{equation}\nMini-batch gradient descent (more than one, but less than all training observations).<br>\n\\begin{equation}1 < n < N_{training} \\end{equation} \nBatch gradient descent (all training observations).<br>\n\\begin{equation}n = N_{training}\\end{equation} ","metadata":{}},{"cell_type":"code","source":"#Number of classification categories\nQ <-10\n\n#Total number of observations\nN <-nrow(Data)\n\n#Percent of training observations\nPercent <-0.9  \n\n#Training observations\nN_training <-N*Percent\n\n#Testing observations\nN_testing <-N-N_training","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:25:12.698812Z","iopub.execute_input":"2024-02-28T14:25:12.700603Z","iopub.status.idle":"2024-02-28T14:25:12.724012Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Separate training and testing data.","metadata":{}},{"cell_type":"code","source":"# Randomly select N_training observations from the total N observations.\n# Randomly select N_training rows\n# replace = TRUE means that the same row can be selected more than once.\n# replace = FALSE means that the same row cannot be selected more than once.\nRandomly_selected_rows <-sample(nrow(Data), N_training, replace = FALSE)\n\n# Create a new matrix with the selected rows\nData_training <-Data[Randomly_selected_rows, ]\n\n# Get the remaining rows\nremaining_rows <-setdiff(seq_len(nrow(Data)), Randomly_selected_rows)\n\n# Create a new matrix with the remaining rows\nData_testing <-Data[remaining_rows, ]","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:25:15.848799Z","iopub.execute_input":"2024-02-28T14:25:15.850698Z","iopub.status.idle":"2024-02-28T14:25:16.399205Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's separate the **y** column and the **image vector columns**.","metadata":{}},{"cell_type":"code","source":"#Training data\nY_Labels_training <-Data_training[, 1]  %>% as.matrix()  %>% t()\n\nRow_Image_Matrix_training <-Data_training[, 2:ncol(Data_training)]  %>%  as.matrix()\n\n#Testing data\nY_Labels_testing <-Data_testing[, 1]  %>% as.matrix()  %>% t()\n\nRow_Image_Matrix_testing <-Data_testing[, 2:ncol(Data_testing)]  %>%  as.matrix()","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:25:19.964742Z","iopub.execute_input":"2024-02-28T14:25:19.966642Z","iopub.status.idle":"2024-02-28T14:25:20.397108Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Scale Pixel Input Data\n\nWhy does the pixel input data need to be scaled? One reason is to prevent<br>\nnumerical overflow for softmax function. The softmax function is< used to<br> \nconvert the output of the neural network into a probability distribution.<br> \nThe softmax function becomes numerically unstable with very large values.<br> \nThousands of inputs for softmax quickly explodes softmax output value.<br> \nScaled input values helps to prevent numerical overflow for softmax.<br> \nAnother reason is to redude the number of iterations needed for the<br> \nneural network convergence. The neural network converges faster with<br> \nscaled input data.\n\n\nAfter splitting the data into training and testing data. We need to scale<br>\nthe data. Calculate statistical values from training data (e.g. mean,<br> \nstandard deviation, min-max values, etc.). Then use these values to scale<br> \ntraining and testing data with the same statistical values. This is to<br> \nprevent data leakage from testing data to training data. In other words.<br> \nWe obtain consistency and reliable performance evaluations for the model.<br> \n\n#### Generalized min-max normalization.\nWe can scale between any two numbers with the general min-max<br>\nnormalization formula. Input data is between lower and upper bounds. 0<br>\nand 1 are the most common used lower and upper bounds. The generalized<br>\nmin-max normalization formula is defined as follows:<br>\n\n\\begin{equation} Rescale = lowerbound + \\frac{[(i - i_{min})*(upperbound - lowerbound)]}{i_{range}} \\end{equation}\n\nPixels values $i$ are between 0 and 255.<br>\nRescaled pixel values can be between any number (e.g. 0 and 1).<br>\n\n#### Standardized z-score normalization.\nAnother way to scale the pixel input data is to use the standardized<br>\nz-score normalization formula. The standardized z-score normalization<br>\nformula is defined as follows:<br>\n\n\\begin{equation} Rescale = \\frac{i - \\mu}{\\sigma} \\end{equation}\n\nWhere:<br>\n\n\\begin{equation} i = \\text{pixel value} \\end{equation}\n\n\\begin{equation} \\mu = \\text{mean of pixel values} \\end{equation}\n\n\\begin{equation} \\sigma = \\text{standard deviation of pixel values} \\end{equation}\n","metadata":{}},{"cell_type":"code","source":"# Set the scale_var to 0 for generalized min-max normalization.\n# Set the scale_var to 1 for standardized z-score normalization.\n\nscale_var <-1\n\nif (scale_var == 0) {\n##############################\n# Generalized min-max normalization.\n##############################\ni_min <- min(Row_Image_Matrix_training)\ni_range <- max(Row_Image_Matrix_training) - i_min\nlower_bound <- 0  # set your desired lower bound\nupper_bound <- 1  # set your desired upper bound\n\n#Rescale training matrix.\nRow_Image_Matrix_training <-lower_bound + (((Row_Image_Matrix_training - i_min) * (upper_bound - lower_bound)) / i_range)\n\n#Rescale test matrix.\n# Use the same statistical values from training data to scale testing data.\nRow_Image_Matrix_testing <-lower_bound + (((Row_Image_Matrix_testing - i_min) * (upper_bound - lower_bound)) / i_range)\n\n} else {\n##############################\n# Standardized z-score normalization.\n##############################\n###############\n# Rescale training matrix.\n###############\n# mean of training data\nmean_training <-mean(Row_Image_Matrix_training)\n\n# Calculate the sample standard deviation \nsd_training <- sd(Row_Image_Matrix_training)\n\n#Rescale training matrix.\n# Standardize training data using the sample standard deviation and mean\nRow_Image_Matrix_training <- (Row_Image_Matrix_training - mean_training) / sd_training\n\n###############\n# Rescale testing matrix.\n###############\n# Rescale test matrix.\n# Use the same statistical values from training data to scale testing data.\nRow_Image_Matrix_testing <- (Row_Image_Matrix_testing - mean_training) / sd_training\n\n}\n\n#Scaled Training/Testing data.\n# Bind Y_Labels_training and Row_Image_Matrix_training \nData_training_scaled <-cbind(t(Y_Labels_training), Row_Image_Matrix_training)  %>% as.matrix() \n\n# Bind Y_Labels_testing and Row_Image_Matrix_testing\nData_testing_scaled <-cbind(t(Y_Labels_testing), Row_Image_Matrix_testing)  %>% as.matrix()","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:25:24.239324Z","iopub.execute_input":"2024-02-28T14:25:24.241304Z","iopub.status.idle":"2024-02-28T14:25:25.459238Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feedforward \n### No Mapping in Neural Networks\nThe M weight matrix is a matrix of random numbers. The multiplication of<br> \nthe M and X matrix creates planes in **d** dimensions. A neural network is<br> \nnothing more than the optimization of planes in **d** dimensions. The<br> \nplanes in **d** dimensions cross through some point **b** on the **y-axis**.<br>\nWhat does no mapping mean? It means that input data is not transformed by<br>\nany function. In other words, the input X matrix is simply.<br>\n\n\\begin{equation} X_{i} = X_{d} \\end{equation}\n\nWhereas neural networks with Fourier Feature mapping, the input X matrix<br>\nis transformed by some function. In other words, the input X matrix is.<br>\n\n\\begin{equation} X_{i} = \\gamma(X_{d})\\end{equation} \n\nNote that $X_{i}$ is shorthand for $X_{input}$ and $X_{d}$ is shorthand for $X_{data}$.<br>\n\n### Fourier Feature Mapping in Neural Networks\nFourier feature mapping means that the neural network is trained on the<br> \nscaled pixel values that are first passed through a Fourier transform.<br> \nThe Fourier series is defined as:<br>\n\n\\begin{equation} f(x) = a_{0} + \\sum_{n=1}^{\\infty} \\left[ a_{n}\\cos\\left(\\frac{2\\pi nx}{f}\\right) + b_{n}\\sin\\left(\\frac{2\\pi nx}{f}\\right) \\right] \\end{equation}\n\nwhere:<br>\n\n\\begin{equation} f = \\text{frequency} \\end{equation}\n\n\\begin{equation} H = 1\\ 2\\ 3\\ 4\\ \\ldots\\ n = \\text{harmonic numbers}\\end{equation}\n\nI will build up to the Fourier series. Not the most mathematically<br> \nrigorous explanation, but it will do. First define the input vector $(X_{d})_{v}$<br>\nas a single observation. The input vector is size 1 x n. For Mnist<br>\ndataset, input vector is size 1 x 784. Next, pass the input vector through<br> \nan alternating sine cos function $\\gamma(X_{d})_{v}$.<br>\n\n\\begin{equation} \\gamma(X_{d})_{v} = \\cos\\left(\\frac{\\pi x_{1d}}{f_{1}}\\right) + \\sin\\left(\\frac{2\\pi x_{2d}}{f_{2}}\\right)  + \\cdots + \\cos\\left(\\frac{\\pi nx_{nd}}{f_{n}}\\right) + \\sin\\left(\\frac{\\pi nx_{nd}}{f_{n}}\\right)  \\end{equation}\n\nPass $\\gamma(X_{d})_{v}$ matrix through the bias operator.<br>\n\n\\begin{equation} \\gamma(X_{d})_{v} \\underset{bias}{\\rightarrow} X1_{v} = 1 + \\cos\\left(\\frac{\\pi x_{1d}}{f_{1}}\\right) + \\sin\\left(\\frac{2\\pi x_{2d}}{f_{2}}\\right)  + \\cdots + \\cos\\left(\\frac{\\pi nx_{nd}}{f_{n}}\\right) + \\sin\\left(\\frac{\\pi nx_{nd}}{f_{n}}\\right) \\end{equation}\n\nCos and sine map onto the x values for the X matrix. Note that $x_{b} = 1$,<br>\nwhich represents the bias node.<br>\n\n\\begin{equation} X1_{v}=1 + \\cos\\left(\\frac{\\pi x_{1d}}{f_{1}}\\right) + \\sin\\left(\\frac{2\\pi x_{2d}}{f_{2}}\\right)  + \\cdots + \\cos\\left(\\frac{\\pi nx_{nd}}{f_{n}}\\right) + \\sin\\left(\\frac{\\pi nx_{nd}}{f_{n}}\\right) \\end{equation}\n\n\\begin{equation} X1_{v}= 1 + x_{1} + x_{2} + \\cdots + x_{n} \\end{equation}\n\nMultiply M weight vector by X1 vector.<br>\n\n\\begin{equation} M_{v}X1_{v} =w_{b}(1) + w_{1}\\cos\\left(\\frac{\\pi x_{1d}}{f_{1}}\\right) + w_{2}\\sin\\left(\\frac{2\\pi x_{2d}}{f_{2}}\\right)  + \\cdots + w_{n}\\cos\\left(\\frac{\\pi nx_{nd}}{f_{n}}\\right) + w_{n}\\sin\\left(\\frac{\\pi nx_{nd}}{f_{n}}\\right)  \\end{equation}\n\n\\begin{equation} M_{v}X1_{v} = w_{b}(1) + w_{1}x_{1} + w_{2}x_{2} + \\cdots + w_{n}x_{n} \\end{equation}\n\n$M_{v}X1_{v}$ can be seen as a Fourier series. $w_{cos}$ are weights that<br>\ncorrespond to the cosine terms. $w_{sin}$ are weights that correspond to<br>\nthe sine terms. $w_{b}$ is the bias weight. The Fourier series can be<br>\nwritten as:<br>\n\n\\begin{equation} M_{v}X1_{v} = w_{b}(1) + \\sum_{n=1}^{\\infty} \\left[ w_{cos}\\cos\\left(\\frac{2\\pi nx}{f}\\right) + w_{sin}\\sin\\left(\\frac{2\\pi nx}{f}\\right) \\right] \\end{equation}\n\nIn the papaer, \"Fourier Features Let Networks Learn High Frequency<br>\nFunctions in Low Dimensional Domains\" by Tancik et al. The authors<br>\nrecommend setting the frequency as ramdom points from a Gaussian<br>\ndistribution $\\mathcal{N}(0,\\sigma^{2})$. What does ramdomly sampling points from<br>\na Gaussian distribution mean? Let's say that $\\sigma = 1$, which is about 68%<br>\nof the area under the curve. Then at $\\sigma = 1$ means that points are<br>\nrandomly sampled from about 68% area under the curve. Let's say that $\\sigma = 2$,<br> \nwhich means that points are randomly sampled from about 95% of the area<br>\nunder the curve. So on and so forth. The higher the sigma value, then<br>\nthere's more area under the curve that can be randomly sampled for the<br>\nB vector.<br>\n\n\\begin{equation} f = B = \\text{randomly sampled points from a Gaussian distribution} \\end{equation}\n\nThus applying H (harmonic numbers) and B to $\\gamma(X_{d})_{v}$, you get<br>\nfourier feature mapping.<br>\n\n\\begin{equation} X_{i} = \\gamma(X_{d})_{v} =  \\left[ \\cos\\left({H\\pi B x}\\right), \\sin\\left({H\\pi B x}\\right) \\right]^T \\end{equation}\n\n### X Input Matrix Preparation\nFor no mapping use regular pixel values. For Fourier feature mapping use<br> \nFourier series scaled pixel values. X training matrix for batch gradient<br> \ndescent is simply the transpose of the image matrix.<br> \n\n\\begin{equation}  X1_{training} = Transpose(Image Matrix) = \\begin{bmatrix}\npixel0 & pixel28 & pixel56 & \\cdots & pixel756 \\\\\npixel1 & pixel29 & pixel57 & \\cdots & pixel757 \\\\\npixel2 & pixel30 & pixel58 & \\cdots & pixel758 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\npixel27 & pixel55 & pixel83 & \\cdots & pixel783 \\\\\n\\end{bmatrix} \\end{equation}\n\nNote that observation is used as a synonym for training example. For<br> \nstochastic gradient descent. We randomly select 1 observation from<br> \ntraining data. Then transpose to make each column an observation. For<br> \nmini-batch gradient descent, we randomly select some n random observations<br> \nfrom training data. Then transpose the resulting matrix to make each<br> \ncolumn an observation.<br>\n\nFor example, let's say we randomly select 3 observations (n=3) from<br> \ntraining data. Then transpose to make each column as an observation.<br>\n\n\\begin{equation}  X1_{training} = \\begin{bmatrix}\nobservation24147 & observation587 & observation13371\\\\\n\\end{bmatrix}  \\end{equation}\n\n\\begin{equation}  Transpose(Image Matrix) = \\begin{bmatrix}\npixel0 & pixel28 & pixel56 \\\\\npixel1 & pixel29 & pixel57 \\\\\npixel2 & pixel30 & pixel58 \\\\\n\\vdots & \\vdots & \\vdots \\\\\npixel27 & pixel55 & pixel83 \\\\\n\\end{bmatrix} \\end{equation}\n\nNote that I set the columns of the X1 matrix to be observations. One can<br>\nlikewise set the rows of the X1 matrix to be observations. It doesn't<br> \nmatter if the rows or columns are set as observations. The important<br> \nthing is to be consistent throughout the the mathematical derivation and<br> \nthe implemented code.<br>\n\n### Simplification of Weight and Input Matrice\nWith every layer with an activation function, the none bias input X<br>\nmatrix is multiplied by the none bias weight matrix. Then the bias input<br>\nX matrix is multiplied by the bias weight matrix. Then the two resulting<br>\nmatrices are added together. Here's a question, can we simplify the<br> \nmultiplication of the weight and input matrices? The answer is yes.<br>\nBefore passing through the LeakyReLU activation function. The weight<br> \nmatrix and input matrices can be simplified as follows:<br> \n\n\\begin{equation} m_{m \\; x \\; n} * x_{n \\; x \\; p} + m_{bias, m \\; x \\; 1 } * x_{bias, 1 \\; x \\; p} = MX_{m \\; x \\; p} \\end{equation}\n\nFor example:\n\\begin{equation} \\begin{bmatrix}\nw1 & w2 \\\\\nw3 & w4\\\\\n\\end{bmatrix}_{m \\; x \\; n} *  \\begin{bmatrix}\nx1 & x3 \\\\\nx2 & x4\\\\\n\\end{bmatrix}_{n \\; x \\; p} + \\begin{bmatrix}\nwb1 \\\\\nwb2 \\\\\n\\end{bmatrix}_{m \\; x \\; 1} *  \\begin{bmatrix}\nxb1 & xb2 \\\\\n\\end{bmatrix}_{1 \\; x \\; p} = \\end{equation}\n\n\\begin{equation} \\left[\\begin{array}{cc}\nw1 & w2 \\\\\nw3 & w4 \\\\\n\\end{array}\\right.\n\\left.\\begin{array}{c}\n\\begin{bmatrix}\nwb1 \\\\\nwb2 \\\\\n\\end{bmatrix}\n\\end{array}\\right]_{m \\; x \\; (n+1)}\n*  \n\\begin{bmatrix}\nx1 & x3\\\\\nx2 & x4\\\\\n[xb1 & xb2]\\\\\n\\end{bmatrix}_{(n+1) \\; x \\; p} \\end{equation}\n\nWhere:\n\\begin{equation} \\begin{bmatrix}xb1 & xb2 = 1 & 1 \\end{bmatrix} \\end{equation}\nThus:\n\n\\begin{equation} \\left[\\begin{array}{cc}\nw1 & w2 \\\\\nw3 & w4 \\\\\n\\end{array}\\right.\n\\left.\\begin{array}{c}\n\\begin{bmatrix}\nwb1 \\\\\nwb2 \\\\\n\\end{bmatrix}\n\\end{array}\\right]_{m \\; x \\; (n+1)}\n*  \n\\begin{bmatrix}\nx1 & x3\\\\\nx2 & x4\\\\\n[1 & 1]\\\\\n\\end{bmatrix}_{(n+1) \\; x \\; p} = MX_{m \\; x \\; p} \\end{equation}\n\nDefine the bias operator as adding a row of ones to the input matrix.<br>\n\n\\begin{equation} x_{n \\; x \\; p} \\underset{bias}{\\rightarrow} X_{(n + 1) \\; x \\; p} \\end{equation}\n\nAs the previous example shows:\n\\begin{equation} \\begin{bmatrix}\nx1 & x3 \\\\\nx2 & x4\\\\\n\\end{bmatrix}_{n \\; x \\; p} \\underset{bias}{\\rightarrow} \\begin{bmatrix}\nx1 & x3\\\\\nx2 & x4\\\\\n[1 & 1]\\\\\n\\end{bmatrix}_{(n+1) \\; x \\; p} \\end{equation}\n\nTherefore, instead of doing two operations. That is to say. Multiplying<br> \nbias matrix and non-bias matrix by their corresponding input matrices,<br> \nthen adding the multiplied matrices. Both weight matrix and input matrix<br> \ncan be combined into one weight and one input matrix. Thus, simplifying<br> \nthe computation into one operation.<br>\n\n### LeakyReLU Activation Function\nActivation functions in the hidden layers are used to introduce non-linearity<br>\ninto the neural network. LeakyReLU was chosen because of it's simplicity<br>\nand it's ability to prevent the dying ReLU problem. The dying ReLU problem<br>\nis when the ReLU activation function outputs 0 for all negative inputs.<br> \nThus, the gradient becomes 0 and the network cannot perform backpropagation.<br>\nLeakyReLU solves this problem by having a small positive slope for negative<br>\ninputs. Note that setting alpha to 0 makes LeakyReLU the same as ReLU.<br>\nHence LeakyReLU is the more general form of ReLU. The LeakyReLU activation<br> \nfunction is simply a piecewise function which is defined as follows:<br>\n\n\\begin{equation} LeakyReLU(x) = \n\\begin{cases} \n\\alpha*x & \\text{if } x < 0  \\\\\nx & \\text{if } x \\geq 0\n\\end{cases} \\end{equation}\n\nPlot for LeakyReLU.<br>","metadata":{}},{"cell_type":"code","source":"leaky_relu <- function(x, alpha = 0.05) {\n  ifelse(x > 0, x, alpha * x)\n}\n\ncurve(leaky_relu, from = -5, to = 2, xlab = \"x\", ylab = \"Leaky ReLU(x)\", main = \"Leaky ReLU Activation Function\")\nabline(h = 0, v = 0, col = \"black\", lwd = 2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:25:33.04194Z","iopub.execute_input":"2024-02-28T14:25:33.046478Z","iopub.status.idle":"2024-02-28T14:25:33.348502Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Softmax Activation Function\nThe softmax activation function is used to convert the output of the<br>\nneural network into a probability distribution. Softmax essentially<br> \npredicts the probability that an observation belongs to a particular<br> \nclass. The softmax function is defined as follows:<br>\n\n\\begin{equation} Softmax(z) = \\frac{e^{z_{i}}}{\\sum_{j=1}^{Q} e^{z_{j}}} \\end{equation}\n\nAs previously stated:<br>\n\\begin{equation} NumberClasses  = Q = 10 \\end{equation} \n\nFor better numerical stability, the softmax function is modified as follows:<br>\n\n\\begin{equation} Softmax(z)_{Max}  = \\frac{e^{z_{i} - max(z)}}{\\sum_{j=1}^{Q} e^{z_{j} - max(z)}} \\end{equation}\n\nTaking log of both sides:<br>\n\n\\begin{equation} ln[Softmax(z)_{Max}] = ln\\left(\\frac{e^{z_{i} - max(z)}}{\\sum_{j=1}^{Q} e^{z_{j} - max(z)}}\\right) \\end{equation}\n\nApply the log identity to the softmax function:<br>\n\n\\begin{equation} ln(\\frac{a}{b}) =ln(a) - ln(b) \\end{equation}\n\n\\begin{equation} ln(Softmax(z)_{Max}) =  ln\\left[e^{z_{i} - max(z)}\\right] - ln\\left[\\sum_{j=1}^{Q} e^{z_{j} - max(z)}\\right] \\end{equation}\n\n\\begin{equation} ln(Softmax(z)_{Max}) =  z_{i} - max(z) - ln\\left[\\sum_{j=1}^{Q} e^{z_{j} - max(z)}\\right] \\end{equation}\n\n\\begin{equation} e^{ln(Softmax(z)_{Max})}  = e^{z_{i} - \\max(z) - ln\\left[\\sum_{j=1}^{Q} e^{z_{j} - max(z)}\\right]} \\end{equation}\n\nAfter some algebraic manipulation, the final version of the softmax function is redefined<br>\nas follows:<br>\n\n\\begin{equation} Softmax(z)_{Max}  = e^{z_{i} - \\max(z) - ln\\left[\\sum_{j=1}^{Q} e^{z_{j} - max(z)}\\right]} \\end{equation}\n\n### One Hot Encoding Matrix\nThe output of the NN is a vector of 10 probabilities, each probability<br>\nrepresents the probability of the image being a digit from 0 to 9. But<br>\nY_Labels is not a vector of probabilities, it's a vector of digits. Hence,<br> \nY_Labels needs to be converted into a vector of probabilities. This is<br>\ndone by using one-hot encoding.<br>\n\nSince I set the columns of the X1 matrix to be observations. Then each<br>\ncolumn of the one hot encoding matrix is also an observation. The one hot<br>\nencoding matrix is a matrix of zeros with only a single 1 in each column.<br>\nMathematically you can think of each column as a basis vector. In other<br>\nwords, each column is a vector of zeros with only a single 1. The position<br>\nof the 1 represents the class. Thus each column represents an observation.<br>\nNeural network is trained to classify images of digits from 0 to 9. Thus<br>\nrow 1 represents digit 0, row 2 represents digit 1, row 3 represents<br>\ndigit 2, so on and so forth. Example of one hot encoding matrix for Q=10<br> \nclasses and n=5 observations is as follows:<br>\n\n\\begin{equation} Y_{Q \\; x \\; n} = \\text{One Hot Encoding Matrix} \\end{equation}<br>\n\n\\begin{equation} Y_{Q \\; x \\; n} = \\begin{bmatrix}\n1 & 0 & 0 & 0 & 0 \\\\ \n0 & 0 & 0 & 0 & 0 \\\\ \n0 & 0 & 0 & 0 & 0 \\\\ \n0 & 0 & 0 & 1 & 0 \\\\ \n0 & 0 & 0 & 0 & 1 \\\\ \n0 & 0 & 1 & 0 & 0 \\\\ \n0 & 0 & 0 & 0 & 0 \\\\ \n0 & 0 & 0 & 0 & 0 \\\\ \n0 & 1 & 0 & 0 & 0 \\\\ \n0 & 0 & 0 & 0 & 0 \\\\ \n\\end{bmatrix} \\end{equation}<br>\n\nOne Hot Encoding Training Data<br>","metadata":{}},{"cell_type":"code","source":"# Initialize a list to store the basis vectors\nbasis_vectors_list_training <-list()\n\n# Loop over each column of the matrix\nfor (q in 1:N_training) {\n  # Get the label for the q-th column\n  label <- Y_Labels_training[1, q] %>% as.numeric()\n  \n  # Create a vector of zeros with length Q\n  basis_vectors_training <- rep(0, Q)\n  \n  # Set the (label+1)-th element to 1\n  basis_vectors_training[label + 1] <-1\n  \n  # Add the basis vector to the list\n  basis_vectors_list_training[[q]] <-basis_vectors_training %>% as.matrix()\n}\n\n# Convert the list of basis vectors to a matrix\nY_One_Hot_Encoding_training <- do.call(cbind, basis_vectors_list_training)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:25:38.211202Z","iopub.execute_input":"2024-02-28T14:25:38.213812Z","iopub.status.idle":"2024-02-28T14:25:38.91847Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"One Hot Encoding Testing Data<br>","metadata":{}},{"cell_type":"code","source":"# Initialize a list to store the basis vectors\nbasis_vectors_list_testing <-list()\n\n# Loop over each column of the matrix\nfor (q in 1:N_testing) {\n  # Get the label for the q-th column\n  label <-Y_Labels_testing[1, q] %>% as.numeric()\n  \n  # Create a vector of zeros with length Q\n  basis_vectors_testing <-rep(0, Q)\n  \n  # Set the (label+1)-th element to 1\n  basis_vectors_testing[label + 1] <-1\n  \n  # Add the basis vector to the list\n  basis_vectors_list_testing[[q]] <-basis_vectors_testing %>% as.matrix()\n}\n\n# Convert the list of basis vectors to a matrix\nY_One_Hot_Encoding_testing <- do.call(cbind, basis_vectors_list_testing)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:25:45.437586Z","iopub.execute_input":"2024-02-28T14:25:45.439385Z","iopub.status.idle":"2024-02-28T14:25:45.546507Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Categorical Cross Entropy Loss Function\nThe output from the softmax function is passed to the categorical cross<br>\nentropy loss function. The purpose of the categorical cross entropy loss<br>\nfunction is to measure the difference between the predicted probabilities<br>\nand the actual probabilities. Note that the hollow circle means hadamard<br>\nproduct (element-wise multiplication). After the hadamard product, the<br>\ncategorical cross entropy loss function is summed across **Q** classes<br> \nand then summed over **n** observations. Finally, the sum is divided by<br> \nthe number of observations. The mean categorical cross entropy loss<br> \nfunction is defined as follows:<br>\n\n\\begin{equation} C_{mean} = -\\frac{1}{n} \\sum^{n} \\sum^{Q} [Y_{Q \\; x \\; n} \\circ \\ln(X_{out})_{Q \\; x \\; n}] \\end{equation}<br>\n\n\\begin{equation} C_{mean} = -mean\\left[ \\sum^{Q} [Y_{Q \\; x \\; n} \\circ \\ln(X_{out})_{Q \\; x \\; n}] \\right] \\end{equation}<br>\n\nCost function for each observation is a vector.<br>\n\\begin{equation} C_{vector} = C_{v} = -[y_{v} \\circ \\ln(x_{out})_{v}] \\end{equation}<br>\n\nAll cost function vectors make up the cost function matrix.<br>\n\\begin{equation} C_{Matrix} = C_{M} = -Y_{Q \\; x \\; n} \\circ \\ln(X_{out})_{Q \\; x \\; n} \\end{equation}\n\n### Feedforward Summary\n\\begin{equation} NumberPixels  = 784 \\end{equation}<br>\n\\begin{equation} NumberObservations  = n \\end{equation}<br>\n\\begin{equation} NumberClasses  = Q = 10 \\end{equation}<br>\n\n#### When Using One Hidden Layer\n\\begin{equation} \\text{Number Hidden Neurons}= nu \\end{equation} <br>\n\n\\begin{equation} Xi_{784 \\; x \\; n}  \\underset{bias}{\\rightarrow}  (X1)_{(784+1) \\; x \\; n}   \\end{equation} <br>\n\\begin{equation} (M1)_{nu \\; x \\; 785} * (X1)_{785 \\; x \\; n}  = (Z2)_{nu \\; x \\; n} \\end{equation}<br>\n\\begin{equation} LR[(Z2)]_{nu \\; x \\; n}  \\underset{bias}{\\rightarrow}  (X2)_{(nu+1) \\; x \\; n}   \\end{equation}<br>\n\\begin{equation} (M2)_{Q \\; x \\; (nu+1)} * (X2)_{(nu+1) \\; x \\; n}  = (Z3)_{Q \\; x \\; n} \\end{equation}<br>\n\\begin{equation} (Z3)_{Q \\; x \\; n}  = (Z_{out})_{Q \\; x \\; n}\\end{equation}<br>\n\n#### When Using Two Hidden Layers\n\\begin{equation} \\text{Number Hidden Neurons 1st layer }= nu \\end{equation} <br> \n\\begin{equation} \\text{Number Hidden Neurons 2nd layer }= nu2 \\end{equation} <br>\n\n\\begin{equation} Xi_{784 \\; x \\; n}  \\underset{bias}{\\rightarrow}  (X1)_{(784+1) \\; x \\; n}   \\end{equation}<br>\n\\begin{equation} (M1)_{nu \\; x \\; 785} * (X1)_{785 \\; x \\; n}  = (Z2)_{nu \\; x \\; n} \\end{equation}<br>\n\\begin{equation} LR[(Z2)]_{nu \\; x \\; n}  \\underset{bias}{\\rightarrow}  (X2)_{(nu+1) \\; x \\; n}   \\end{equation}<br>\n\\begin{equation} (M2)_{nu2 \\; x \\; (nu+1)} * (X2)_{(nu+1) \\; x \\; n}  = (Z3)_{nu2 \\; x \\; n} \\end{equation}<br>\n\\begin{equation} LR[(Z3)]_{nu2 \\; x \\; n}  \\underset{bias}{\\rightarrow}  (X3)_{(nu2+1) \\; x \\; n}   \\end{equation}<br>\n\\begin{equation} (M3)_{Q \\; x \\; (nu2+1)} * (X3)_{(nu2+1) \\; x \\; n}  = (Z4)_{Q \\; x \\; n} \\end{equation}<br>\n\\begin{equation} (Z4)_{Q \\; x \\; n}  = (Z_{out})_{Q \\; x \\; n}\\end{equation}<br>\n\n#### Output Layer\n\\begin{equation} [Softmax(Z_{out})_{Max}]_{Q \\; x \\; n}  = (X_{out})_{Q \\; x \\; n} \\end{equation}<br>\n\n\\begin{equation} C_{Matrix} = C_{M} = -Y_{Q \\; x \\; n} \\circ \\ln(X_{out})_{Q \\; x \\; n} \\end{equation}<br>\n\\begin{equation} C_{mean} = -mean\\left[ \\sum^{Q} [Y_{Q \\; x \\; n} \\circ \\ln(X_{out})_{Q \\; x \\; n}] \\right] \\end{equation}<br>\n\n## Backpropagation \nThis is where the magic happens. Backpropagation is where the neural<br> \nnetwork learns. The neural network learns by minimizing the cost function.<br> \nThe cost function is minimized by calculating the gradient of the cost<br> \nfunction with respect to the M weight matrices. The gradient of the cost<br> \nfunction is calculated by using the chain rule. The chain rule is used to<br> \ncalculate the partial derivatives of the cost function with respect to<br> \nthe M weight matrices. Backpropagation is nothing more than finding the<br> \npartial derivative of the cost function with respect to the M weight<br> \nmatrices.I did this via the partial derivative tree diagram. The partial<br> \nderivative tree diagram is a visual representation of the chain rule.<br>\n\n### One Hidden Layer\n#### Derivative of The C Cost Matrix With Respect to The M2 Weight Matrix\n\n\\begin{equation} \\frac{\\partial C}{\\partial M2} = \\left( \\frac{\\partial C^T}{\\partial X3} * \\frac{\\partial X3^T}{\\partial Z3} \\right)^T * \\frac{\\partial Z3}{\\partial M2} \\end{equation}<br>\n\nwhere:<br>\n\n\\begin{equation} \\left(\\frac{\\partial C^T}{\\partial X3} * \\frac{\\partial X3^T}{\\partial Z3}\\right)^T = (X3 - Y)_{Q \\; x \\; n} \\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial Z3}{\\partial M2} = (X2^T)_{n \\; x \\; (nu +1)} \\end{equation}<br>\n\nthus:<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial M2} = (X3 - Y)_{Q \\; x \\; n} * (X2^T)_{n \\; x \\; (nu+1)} \\end{equation}<br>\n\nThe matrix (X3 - Y) is obtained by the matrix multiplication of the softmax<br>\nJabobian matrix with the derivative of the C cost vector with respect to<br>\nthe output softmax vector.<br>\n\nFor sanity check, the size of the M2 weight matrix must equal the size of<br>\nthe derivative of the C cost matrix with respect to the M2 weight matrix.<br>\n\nSize of M2 matrix is:<br>\n\n\\begin{equation} (M2)_{size}= Q \\; x \\; (nu+1) \\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial M2}_{size} = (Q \\; x \\; n) * (n \\; x \\; (nu+1)) \\end{equation}<br>\n\\begin{equation} \\frac{\\partial C}{\\partial M2}_{size} = Q \\; x \\; (nu+1) \\end{equation}<br>\n\n\\begin{equation} (M2)_{size} = \\frac{\\partial C}{\\partial M2}_{size} \\end{equation}<br>\n\n#### Derivative of The C Cost Matrix With Respect to The M1 Weight Matrix\n\n\\begin{equation} \\frac{\\partial C}{\\partial M1} = \\left[ \\left( \\left( \\frac{\\partial C^T}{\\partial X3} * \\frac{\\partial X3^T}{\\partial Z3} \\right) * \\frac{\\partial Z3}{\\partial X2} \\right)^T \\circ \\frac{\\partial X2}{\\partial Z2} \\right] * \\frac{\\partial Z2}{\\partial M1}\\end{equation}<br>\n\nwhere:<br>\n\n\\begin{equation} \\left( \\frac{\\partial C^T}{\\partial X3} * \\frac{\\partial X3^T}{\\partial Z3} \\right) = (X3 - Y)^T_{n \\; x \\; Q} \\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial Z3}{\\partial X2}= (M2_{-b})_{Q \\; x \\; nu} \\end{equation} <br>\n\nThe subscript -b means that the bias column is removed from the M2 weight<br>\nmatrix. Note that leaky ReLU LR(z) = x2. The bias weights are multiplied<br>\nby 1, hence there is no LR(z) activation function in the bias node. Thus<br>\nwhen you take the derivative of the Z3 matrix with respect to the X2<br>\nmatrix, the bias column is removed because the bias node has no x2<br>\nactivation function. The derivative dZ3/dX2= 0 for the bias column.<br>\n\nYou also have:<br>\n\n\\begin{equation} \\frac{\\partial X2}{\\partial Z2} = {[\\partial LR(X2_{-b})}]_{nu \\; x \\; n}\\end{equation}<br>\n\nSimilarly, the subscript -b means that the bias row is removed from the<br>\nX2 matrix. The bias node has only ones, which are not dependent on previous<br>\nweights. Thus, when you take the derivative of the X2 matrix with respect<br>\nto the Z2 matrix, the bias row is removed because the bias node is not<br>\nconnected to previous nodes. The derivative dX2/dZ2= 0 for the bias row.<br>\n\nYou finally have:<br>\n\n\\begin{equation} \\frac{\\partial Z2}{\\partial M1}= X1^T_{n \\; x \\; 785} \\end{equation}<br>\n\n\nThus you have:<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial M1} = [[(X3 - Y)^T * M2_{-b}]^T \\circ \\partial LR(X2_{-b})] * X1^T \\end{equation}<br>\n\nAgain for sanity check, the size of the M1 weight matrix must equal the<br>\nsize of the derivative of the C cost matrix with respect to the M1 weight<br>\n\nSize of M1 matrix is:<br>\n\n\\begin{equation} (M1)_{size}= nu \\; x \\; 785\\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial M1}_{size} = [[(n \\; x \\; Q)*(Q \\; x \\; nu)]^T \\circ (nu \\; x \\; n)] * (n \\; x \\; 785) \\end{equation}\n\\begin{equation}                               = [(n \\; x \\; nu)^T \\circ (nu \\; x \\; n)] * (n \\; x \\; 785)\\end{equation}\n\\begin{equation}                               = [(nu \\; x \\; n) \\circ (nu \\; x \\; n)] * (n \\; x \\; 785)\\end{equation}\n\\begin{equation}                               = (nu \\; x \\; n) * (n \\; x \\; 785)\\end{equation}\n\\begin{equation} \\frac{\\partial C}{\\partial M1}_{size} = nu \\; x \\; 785\\end{equation}\n\n\\begin{equation} (M1)_{size} = \\frac{\\partial C}{\\partial M1}_{size}\\end{equation}<br>\n\n### Two Hidden Layers\n#### Derivative of The C Cost Matrix With Respect to The M3 Weight Matrix\n\\begin{equation} \\frac{\\partial C}{\\partial M3} = \\left( \\frac{\\partial C^T}{\\partial X4} * \\frac{\\partial X4^T}{\\partial Z4} \\right)^T * \\frac{\\partial Z4}{\\partial M3} \\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial M3} = (X4 - Y)_{Q \\; x \\; n} * (X3)_{n \\; x \\; (nu2+1)}^T \\end{equation}<br>\n\nwhere:<br>\n\n\\begin{equation} \\left(\\frac{\\partial C}{\\partial Z4}\\right)^T = (X4 - Y)_{Q \\; x \\; n} \\end{equation}<br>\n\nFor sanity check, the size of the M3 weight matrix must equal the size of<br>\nthe derivative of the C cost matrix with respect to the M3 weight matrix.<br>\n\nSize of M3 matrix is:<br>\n\n\\begin{equation} (M3)_{size}= Q \\; x \\; (nu2+1) \\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial M3}_{size} = (Q \\; x \\; n) * (n \\; x \\; (nu2+1))\\end{equation}<br>\n\\begin{equation} \\frac{\\partial C}{\\partial M3}_{size} = Q \\; x \\; (nu2+1)\\end{equation}<br>\n\n\\begin{equation} (M3)_{size} = \\frac{\\partial C}{\\partial M2}_{size}\\end{equation}<br>\n\n#### Derivative of The C Cost Matrix With Respect to The M2 Weight Matrix\n\\begin{equation} \\frac{\\partial C}{\\partial M2} = \\left[ \\left( \\left( \\frac{\\partial C^T}{\\partial X4} * \\frac{\\partial X4^T}{\\partial Z4} \\right) * \\frac{\\partial Z4}{\\partial X3} \\right)^T \\circ \\frac{\\partial X3}{\\partial Z3} \\right] * \\frac{\\partial Z3}{\\partial M2}\\end{equation}<br>\n\\begin{equation} \\frac{\\partial C}{\\partial M2} = \\left[ \\left( \\left(\\frac{\\partial C}{\\partial Z4}\\right) * \\frac{\\partial Z4}{\\partial X3} \\right)^T \\circ \\frac{\\partial X3}{\\partial Z3} \\right] * \\frac{\\partial Z3}{\\partial M2}\\end{equation}<br>\n\nwhere:<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial Z3} = \\left( \\left(\\frac{\\partial C}{\\partial Z4}\\right) * \\frac{\\partial Z4}{\\partial X3} \\right)^T  \\circ \\frac{\\partial X3}{\\partial Z3} \\end{equation}<br>\n\nThen:<br>\n\n\\begin{equation} \\frac{\\partial Z4}{\\partial X3}= (M3_{-b})_{Q \\; x \\; nu2} \\end{equation} <br>\n\n\\begin{equation} \\frac{\\partial X3}{\\partial Z3}= {[\\partial LR(X3_{-b})}]_{nu2 \\; x \\; n}\\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial Z3}{\\partial M2}= X2^T_{n \\; x \\; (nu+1)} \\end{equation}<br>\n\nThus you have:<br>\n\\begin{equation} \\frac{\\partial C}{\\partial M2} = \\left[\\left(\\frac{\\partial C}{\\partial Z4} * M3_{-b}\\right)^T \\circ \\partial LR(X3_{-b})\\right] * X2^T \\end{equation}<br>\n\\begin{equation} \\frac{\\partial C}{\\partial M2} = [[(X4 - Y)^T * M3_{-b}]^T \\circ \\partial LR(X3_{-b})] * X2^T \\end{equation}<br>\n\nThe size of the M2 weight matrix must equal the size of the derivative of<br> \nthe C cost matrix with respect to the M2 weight<br>\n\nSize of M2 matrix is:<br>\n\n\\begin{equation} (M2)_{size}= nu2 \\; x \\; (nu + 1)\\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial M2}_{size} = [[(n \\; x \\; Q)*(Q \\; x \\; nu2)]^T \\circ (nu2 \\; x \\; n)] * (n \\; x \\; (nu+1))\\end{equation}\n\\begin{equation}                               = [(n \\; x \\; nu2)^T \\circ (nu2 \\; x \\; n)] * (n \\; x \\; (nu+1))\\end{equation}\n\\begin{equation}                               = [(nu2 \\; x \\; n) \\circ (nu2 \\; x \\; n)] * (n \\; x \\; (nu +1))\\end{equation}\n\\begin{equation}                               = (nu2 \\; x \\; n) * (n \\; x \\; (nu +1))\\end{equation}\n\\begin{equation}\\frac{\\partial C}{\\partial M2}_{size} = nu2 \\; x \\; (nu +1)\\end{equation}\n\n\\begin{equation}(M2)_{size} = \\frac{\\partial C}{\\partial M2}_{size}\\end{equation}<br>\n\n#### Derivative of The C Cost Matrix With Respect to The M1 Weight Matrix\n\\begin{equation} \\frac{\\partial C}{\\partial M1} = \\left[\\left[\\left[ \\left( \\left( \\frac{\\partial C^T}{\\partial X4} * \\frac{\\partial X4^T}{\\partial Z4} \\right) * \\frac{\\partial Z4}{\\partial X3} \\right)^T \\circ \\frac{\\partial X3}{\\partial Z3} \\right]^T * \\frac{\\partial Z3}{\\partial X2}\\right]^T \\circ \\frac{\\partial X2}{\\partial Z2}\\right] * \\frac{\\partial Z2}{\\partial M1}\\end{equation}\n\n\\begin{equation}\\frac{\\partial C}{\\partial M1} = \\left[\\left[ \\left(\\frac{\\partial C}{\\partial Z3}\\right)^T * \\frac{\\partial Z3}{\\partial X2}\\right]^T \\circ \\frac{\\partial X2}{\\partial Z2}\\right] * \\frac{\\partial Z2}{\\partial M1}\\end{equation}<br>\n\nwhere:<br>\n\n\\begin{equation} \\frac{\\partial Z3}{\\partial X2}= (M2_{-b})_{nu2 \\; x \\; nu} \\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial X2}{\\partial Z2}= {[\\partial LR(X2_{-b})}]_{nu \\; x \\; n}\\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial Z2}{\\partial M1}= X1^T_{n \\; x \\; 785} \\end{equation}<br>\n\nThus:<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial M1} = \\left[\\left[ \\left(\\frac{\\partial C}{\\partial Z3}\\right)^T * M2_{-b}\\right]^T \\circ \\partial LR(X2_{-b})\\right] * X1^T \\end{equation}<br>\n\nThe size of the M1 weight matrix must equal the size of the derivative of<br> \nthe C cost matrix with respect to the M1 weight<br>\n\nSize of M1 matrix is:<br>\n\n\\begin{equation} (M1)_{size}= nu \\; x \\; 785\\end{equation}<br>\n\n\\begin{equation} \\frac{\\partial C}{\\partial M1}_{size} = [[(n \\; x \\; nu2)*(nu2 \\; x \\; nu)]^T \\circ (nu \\; x \\; n)] * (n \\; x \\; 785)\\end{equation}\n\\begin{equation}                               = [(n \\; x \\; nu)^T \\circ (nu \\; x \\; n)] * (n \\; x \\; 785)\\end{equation}\n\\begin{equation}                               = [(nu \\; x \\; n) \\circ (nu \\; x \\; n)] * (n \\; x \\; 785)\\end{equation}\n\\begin{equation}                               = (nu \\; x \\; n) * (n \\; x \\; 785)\\end{equation}\n\\begin{equation}\\frac{\\partial C}{\\partial M1}_{size} = nu \\; x \\; 785\\end{equation}\n\n\\begin{equation}(M1)_{size} = \\frac{\\partial C}{\\partial M1}_{size} \\end{equation}\n\n## Gradient Descent\nGradient descent is applied at the end of backpropagation. Gradient<br>\ndescent is an algorithm that minimizes the cost function by iteratively<br> \nupdating the M weight matrices. The M weight matrices are updated by<br>\nsubtracting the M weight matrix by the gradient of the cost function with<br> \nrespect to the M weight matrices multiplied by the learning rate. The<br> \nlearning rate is a hyperparameter that determines the size of the step<br> \ntaken in the direction of the gradient. The learning rate is a<br> \nhyperparameter that needs to be tuned. If the learning rate is too small,<br>\nthen the algorithm will take a long time to converge. If the learning<br> \nrate is too large, then the algorithm will diverge.<br>\n\n### Basic Gradient Descent Algorithm\n\\begin{equation} M_{t+1} = M_{t} - \\alpha \\nabla f(M_{t}) \\end{equation}\n\n\\begin{equation} \\alpha = \\text{learning rate set through trial and error} \\end{equation}\n\n#### One Hidden Layer\nFor the M2 weight matrix:<br>\n\\begin{equation} (M2)_{t+1} = (M2)_{t} - \\alpha \\frac{\\partial C}{\\partial M2} \\end{equation}\n\nFor the M1 weight matrix:<br>\n\\begin{equation} (M1)_{t+1} = (M1)_{t} - \\alpha \\frac{\\partial C}{\\partial M1} \\end{equation}\n\n#### Two Hidden Layers\nFor the M3 weight matrix:<br>\n\\begin{equation} (M3)_{t+1} = (M3)_{t} - \\alpha \\frac{\\partial C}{\\partial M3} \\end{equation}\n\nFor the M2 weight matrix:<br>\n\\begin{equation} (M2)_{t+1} = (M2)_{t} - \\alpha \\frac{\\partial C}{\\partial M2} \\end{equation}\n\nFor the M1 weight matrix:<br>\n\\begin{equation} (M1)_{n+1} = (M1)_{t} - \\alpha \\frac{\\partial C}{\\partial M1} \\end{equation}\n\n### Gradient Descent With Decaying Learning Rate\nBasically the same as the basic gradient descent algorithm, except the<br>\nlearning rate is decaying with each iteration/epoch. Variable t stands<br> \nfor the iteration/epoch number. Where t can refer to the iteration if<br> \nusing SGD or Mini-batch GD. Variable t can refer to the epoch if using<br>\nBatch GD. The learning rate is decaying by a factor of 1/t.<br> \n\n\\begin{equation} \\alpha = \\alpha_{1}*(1/t) \\end{equation}\n\n\\begin{equation} \\alpha_{1} = \\text{learning rate alpha1 set through trial and error} \\end{equation}\n\n\\begin{equation} M_{t+1} = M_{t} - \\alpha \\nabla f(M_{t}) \\end{equation}\n\n### Gradient Descent With Adam Optimizer\nAdam optimizer is a combination of RMSprop and momentum. Adam optimizer<br>\nis a more advanced gradient descent algorithm. Adam optimizer is more<br>\nstable and converges faster than basic gradient descent. Adam optimizer<br>\nis the recommended gradient descent algorithm for neural networks. Beta1 is<br> \ntypically set to 0.9. Beta2 is typically set to 0.999. Epsilon is typically<br>\nset to 10^-8. Adam optimzer is defined as follows:<br>\n\n\\begin{equation} M_{t} = M_{t-1} - \\alpha \\frac{\\hat{v1}_{t}}{\\sqrt{\\hat{v2}_{t}} + \\epsilon} \\end{equation}\n\nInitialize:<br>\n\n\\begin{equation} v1_{0} = 0 \\leftarrow \\text{Initialize 1st Momentum} \\end{equation}\n\\begin{equation} v2_{0} = 0 \\leftarrow \\text{Initialize 2nd Momentum} \\end{equation}\n\\begin{equation} t_{0} = 0 \\leftarrow \\text{Initialize timestep} \\end{equation}\n\\begin{equation} \\beta_{1} = 0.9 \\end{equation}\n\\begin{equation} \\beta_{2} = 0.999 \\end{equation}\n\\begin{equation} \\epsilon = 10^{-8} \\end{equation}\n\\begin{equation} \\alpha = \\text{learning rate set through trial and error} \\end{equation}\n\nNote v at (t-1) is the momentum from the previous iteration/epoch. 1st and<br> \n2nd momentum at any time step t is defined as follows.<br>\n\n\\begin{equation} v1_{t} = \\beta_{1}v1_{t-1} + \\left[(1-\\beta_{1})\\nabla f(M_{t-1})\\right] \\end{equation}\n\n\\begin{equation} v2_{t} = \\beta_{2}v2_{t-1} + \\left[(1-\\beta_{2}) \\left[\\nabla f(M_{t-1})\\right]^2\\right] \\end{equation}\n\n\\begin{equation} \\left[\\nabla f(M_{t-1})\\right]^2 = \\nabla f(M_{t-1}) \\circ \\nabla f(M_{t-1})\\end{equation} \n\n\nNote that Beta1 and Beta2 are raised to the power of t. Hence if t=3, then<br>\n(Beta1)^3 and (Beta2)^3. Bias-corrected 1st and 2nd momentum at any time<br>\nstep t is defined as follows:<br>\n\n\\begin{equation} \\hat{v1}_{t} = \\frac{v1_{t}}{1-\\beta_{1}^{t}} \\end{equation}\n\\begin{equation} \\hat{v2}_{t} = \\frac{v2_{t}}{1-\\beta_{2}^{t}} \\end{equation}\n\n#### One Hidden Layer Adam Optimizer for M2 Weight Matrix \nFor the M2 weight matrix Initialize v1, v2, and t to 0. Then 1st and<br> \n2nd momentum at any time step t for M2 matrix.<br>\n\n\\begin{equation} v1_{t} = \\beta_{1}v1_{t-1} + \\left[(1-\\beta_{1})\\frac{\\partial C}{\\partial M2}\\right] \\end{equation}\n\n\\begin{equation} v2_{t} = \\beta_{2}v2_{t-1} + \\left[(1-\\beta_{2}) \\left[\\frac{\\partial C}{\\partial M2}\\right]^2\\right] \\end{equation}\n\n\\begin{equation} \\left[\\frac{\\partial C}{\\partial M2}\\right]^2 = \\frac{\\partial C}{\\partial M2} \\circ \\frac{\\partial C}{\\partial M2}\\end{equation}\n\nThen calculate Bias-corrected 1st and 2nd momentum at any time step t for M2<br> \nmatrix.<br>\n\n\\begin{equation} \\hat{v1}_{t} = \\frac{v1_{t}}{1-\\beta_{1}^{t}} \\end{equation}\n\\begin{equation} \\hat{v2}_{t} = \\frac{v2_{t}}{1-\\beta_{2}^{t}}  \\end{equation}\n\nFinally, the M2 weight matrix is updated.<br>\n\n\\begin{equation} M2_{t} = M2_{t-1} - \\alpha \\frac{\\hat{v1}_{t}}{\\sqrt{\\hat{v2}_{t}} + \\epsilon} \\end{equation}\n\nNote that $\\hat{v1}_{t}$ and $\\hat{v2}_{t}$ are matrices with same dimension as M2. Hence in the formula, $\\frac{\\hat{v1}_{t}}{\\sqrt{\\hat{v2}_{t}} + \\epsilon}$<br>\nrepresents element-wise division, where each element in $\\hat{v1}_{t}$ is divided by the corresponding element in $\\sqrt{\\hat{v2}_{t}} + \\epsilon$.<br>\n\n\n## Training and Accuracy of Neural Network\n### Training Phase\nWhat is the training phase for NN? The training phase is composed of<br>\nfeedforward, backpropagation, then gradient descent. Then start over<br> \nagain. Feedforward, backpropagation, and finally gradient descent. So on<br> \nand so forth. One iteration of feedforward, backpropagation, and gradient<br>\ndescent through every single observation is called an epoch.So then, after<br> \nhow many epochs do you need to stop training? Training stoppage is<br> \ndetermined by the most optimal solution from the testing dataset. Once the<br> \nminima for the testing data is reached, training is optimized. The minima<br>\nfor the testing data is determined by the mean categorical cross entropy<br>\nloss function.<br>\n\n### Accuracy of Neural Network\n$X_{out}$ is the output probability. Each column is an observation. Assuming<br>\nthat the highest predicted class from each column represents the model's<br> \nfinal classification decision. Then extracting the highest probability<br>\nfrom each column, $(X_{out})_{highest}$ is a vector with the highest<br>\nprobability for each column.<br>\n\n\\begin{equation} X_{out} \\underset{collapse\\;vector}{\\rightarrow} [(X_{out})_{highest}]_{1 \\; x \\;n}  \\end{equation}\n\n$Y$ is the one hot encoding matrix which contains all one hot encoding<br>\nvectors. Matrix $Y$ contains all the correct probabilities for each<br>\nobservation. In theory, if 100% accuracy was ever reached, then element<br> \nwise multiplication of $X_{out} \\circ Y= X_{out}$. But if 100% accuracy<br>\nis not reached, then $X_{out} \\circ Y \\neq X_{out}$. The difference between<br>\n$X_{out} \\circ Y$ and $X_{out}$ is the error. The error is the difference between<br>\nthe predicted probability and the correct probability. $X_{out} \\circ Y$ has mostly<br>\nzeros. Each column only contains one non zero value. Hence if you collapse<br>\n$X_{out} \\circ Y$ into a vector. The collapsed vector contains the correct<br>\npredictions and the incorrect predictions for all observations.<br>\n\n\\begin{equation} (X_{out})_{Q \\; x \\; n} \\circ Y_{Q \\; x \\; n} \\underset{collapse\\;vector}{\\rightarrow} [(X_{out} \\circ Y)_{v}]_{1 \\; x \\;n} \\end{equation}\n\nWe can find out the correct prediction for each observation by subtracting<br>\n$[(X_{out} \\circ Y)_{v}]_{1 \\; x \\;n}$ by $[(X_{out})_{highest}]_{1 \\; x \\;n}$. The zeros in the vector<br> \nmeans the NN made the correct prediction for that observation. The non<br> \nzero values in the vector means the NN made the incorrect prediction for<br>\nthat observation.<br>\n\n\\begin{equation} [[(X_{out})_{highest}]_{1 \\; x \\;n} - (X_{out} \\circ Y)_{v}]_{1 \\; x \\;n}\\end{equation}\n\nCount number of zeros to obtain the number of correct predictions.<br>\n\n\\begin{equation} count([[(X_{out})_{highest}]_{1 \\; x \\;n} - (X_{out} \\circ Y)_{v}]_{1 \\; x \\;n})\\end{equation}\n\nThus accuracy = (count)(100%)/n, where n=total number of observations.<br>\n\n\\begin{equation} Accuracy \\; \\% = \\frac{count}{n} * 100\\%  \\end{equation}\n\n## Setting Up Model Parameters and Data Structures\n### Tunenable Hyperparameters","metadata":{}},{"cell_type":"code","source":"# \"No mapping\" = No mapping\n# \"Feature Mapping\" = Fourier Feature Mapping\nNoMapping_vs_FourierFeatureMapping <-\"No mapping\"\n\n# Sigma value for Gaussian distribution for Fourier Feature Mapping\nsigma <-60\n\n#hyperparameter for learning rate\nAlpha_ONE <-10^-3\n\n#Beta1\nBeta1 <-0.9\n\n#Beta2\nBeta2 <-0.999\n\n#Epsilon\nEpsilon <-10^-8\n\n# Initialize 1st moment at t=1\nv1 <-0\n\n# Initialize 2nd moment at t=1\nv2 <-0\n\n# GRADIENT DESCENT ALGORITHMS \n# \"constant\" = constant learning rate\n# \"decaying\" = decaying learning rate (1/t)\n#     \"adam\" = adam optimizer\ngradient_descent_algorithm <-\"adam\"\n\n#Number of training observations used in each batch.\n# Set n=1 for SGD (1 observation)\n# Set 1 <n< N_training for Mini-batch GD (more than 1, but less than all observations)\n# Set n= N_training, Batch GD (All observation)\nn <-350\n\n# Setting LeakyReLU_alpha = 0 is the same as using ReLU.\nLeakyReLU_alpha <-0.1\n\n# 1 for one hidden layer and 2 for two hidden layers.\n# Code is only set up for one or two hidden layers.\n# Thus 1 and 2 are the only allowed values for num_hidden_layers.\nnum_hidden_layers <-1\n\n# Code not set up for one neuron in hidden layer, thus n=1 is not allowed.\n# Apart from that. Any other positive integer is allowed.\n# Number of hidden neurons in 1st hidden layer.\nnu <-100\n\n# Same as other hidden layer, n=1 is not allowed.\n# Number of hidden neurons in 2nd hidden layer.\nnu2 <-20\n\nif (n < N_training) {\n##############################################\n# SGD AND MINI BATCH GRADIENT DESCENT\n###############################################\n# Total number of observations for training\nTb <-N_training\n\n# Number of observations per iteration\nn_iteration <-n\n\n# Number of batches = number of iterations per epoch\nnumber_batches <-Tb/n_iteration\nnumber_iterations_epoch <-number_batches\n\n# Total Number of epochs\nEpoch <-4\n\n# (Epoch*number_iterations_epoch) = total number of iterations per epoch\nEpochs <-Epoch*number_iterations_epoch\n\n} else {\n###############################################\n#BATCH GRADIENT DESCENT\n###############################################\n# Total Number of epochs\nEpochs <-3\n\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:02.374126Z","iopub.execute_input":"2024-02-28T14:26:02.37596Z","iopub.status.idle":"2024-02-28T14:26:02.425836Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Code set for 3. DONT CHANGE. 3 Randomly selected numbers for feedforward prediction.\nn_prediction <-3  ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:26:06.706398Z","iopub.execute_input":"2024-02-28T14:26:06.708195Z","iopub.status.idle":"2024-02-28T14:26:06.724367Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Weight Matrices","metadata":{}},{"cell_type":"code","source":"if (num_hidden_layers < 2) {\n##############################################\n# ONE HIDDEN LAYER\n###############################################\n# Size of matrix M1.\nM1_m_rows <-nu\nM1_n_col <-ncol(Row_Image_Matrix_training) + 1\n\n# Size of matrix X1.\nX1_m_rows <-ncol(Row_Image_Matrix_training) + 1\nX1_n_col <-n\n\n# Size of matrix Z2.\nZ2_m_rows <-nu\nZ2_n_col <-n\n\n# Size of LeakyReLU.\nLeakyReLU_m_rows <-nu\nLeakyReLU_n_col <-n\n\n# Size of matrix M2.\nM2_m_rows <-Q\nM2_n_col <-nu + 1\n\n# Size of matrix X2\n# Add 1 to the number of rows of LeakyReLU to account for the bias.\nX2_m_rows <-nu + 1\nX2_n_col <-n\n\n# Size of matrix Z3.\nZ3_m_rows <-Q\nZ3_n_col <-n\n\n# Size of Softmax. Where softmax = X3 =X_out\nX3_m_rows <-Q\nX3_n_col <-n\n} else {\n##############################################\n# TWO HIDDEN LAYERS\n###############################################\n# Size of matrix M1.\nM1_m_rows <-nu\nM1_n_col <- ncol(Row_Image_Matrix_training) + 1\n\n# Size of matrix X1.\nX1_m_rows <- ncol(Row_Image_Matrix_training) + 1\nX1_n_col <-n\n\n# Size of matrix Z2.\nZ2_m_rows <-nu\nZ2_n_col <-n\n\n# Size of LeakyReLU.\nLeakyReLU_m_rows <-nu\nLeakyReLU_n_col <-n\n\n# Size of matrix M2.\nM2_m_rows <-nu2\nM2_n_col <-nu + 1\n\n# Size of matrix X2\n# Add 1 to the number of rows of LeakyReLU to account for the bias.\nX2_m_rows <-nu + 1\nX2_n_col <-n\n\n# Size of matrix Z3.\nZ3_m_rows <-nu2\nZ3_n_col <-n\n\n# Size of LeakyReLU2.\nLeakyReLU_2_m_rows <-nu2\nLeakyReLU_2_n_col <-n\n\n# Size of matrix M3.\nM3_m_rows <-Q\nM3_n_col <-nu2 + 1\n\n# Size of matrix X3\nX3_m_rows <-nu2 + 1\nX3_n_col <-n\n\n# Size of matrix Z4.\nZ4_m_rows <-Q\nZ4_n_col <-n\n\n# Size of Softmax. Where softmax = X4 =X_out\nX4_m_rows <-Q\nX4_n_col <-n\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:10.1765Z","iopub.execute_input":"2024-02-28T14:26:10.178285Z","iopub.status.idle":"2024-02-28T14:26:10.201829Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Set seed is used to make sure that the same random numbers are generated<br>\neach time the code is run.<br>","metadata":{}},{"cell_type":"code","source":"set.seed(123)","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:15.083624Z","iopub.execute_input":"2024-02-28T14:26:15.085518Z","iopub.status.idle":"2024-02-28T14:26:15.101567Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Weight matrices.<br>","metadata":{}},{"cell_type":"code","source":"# Define the standard deviation for weight initialization (e.g., 1e-1 for small values)\nweight_sd <- 1e-1\n\nif (num_hidden_layers < 2) {\n  ###############\n  # When using One Hidden Layer\n  ###############\n  M1 <- matrix(rnorm(M1_m_rows * M1_n_col, mean = 0, sd = weight_sd), nrow = M1_m_rows, ncol = M1_n_col)\n  M2 <- matrix(rnorm(M2_m_rows * M2_n_col, mean = 0, sd = weight_sd), nrow = M2_m_rows, ncol = M2_n_col)\n} else {\n  ###############\n  # When using Two Hidden Layers\n  ###############\n  M1 <- matrix(rnorm(M1_m_rows * M1_n_col, mean = 0, sd = weight_sd), nrow = M1_m_rows, ncol = M1_n_col)\n  M2 <- matrix(rnorm(M2_m_rows * M2_n_col, mean = 0, sd = weight_sd), nrow = M2_m_rows, ncol = M2_n_col)\n  M3 <- matrix(rnorm(M3_m_rows * M3_n_col, mean = 0, sd = weight_sd), nrow = M3_m_rows, ncol = M3_n_col)\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:18.120435Z","iopub.execute_input":"2024-02-28T14:26:18.122452Z","iopub.status.idle":"2024-02-28T14:26:18.149682Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Organizing Neural Network Metrics with Lists and Dataframes\nCreate a list to store M matrix for each epoch.<br>","metadata":{}},{"cell_type":"code","source":"if (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\nM1_list <-vector(\"list\", Epochs)\nM2_list <-vector(\"list\", Epochs)\n} else {\n###############\n# When using Two Hidden Layers\n###############\nM1_list <-vector(\"list\", Epochs)\nM2_list <-vector(\"list\", Epochs)\nM3_list <-vector(\"list\", Epochs)\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:21.931952Z","iopub.execute_input":"2024-02-28T14:26:21.933918Z","iopub.status.idle":"2024-02-28T14:26:21.950782Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create an empty dataframe to store the mean categorical cross entropy loss<br>\nfor each epoch.<br>","metadata":{}},{"cell_type":"code","source":"if (n < N_training) {\n#SGD and Mini Batch Gradient Descent\nCCEntropy_Loss <-data.frame(iteration = numeric(Epochs), epoch = numeric(Epochs), CCEL_x_out = numeric(Epochs), CCEL_testing_x_out = numeric(Epochs))\n} else {\n#Batch Gradient Descent\nCCEntropy_Loss <-data.frame(epoch = numeric(Epochs), CCEL_x_out = numeric(Epochs), CCEL_testing_x_out = numeric(Epochs))\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:25.622631Z","iopub.execute_input":"2024-02-28T14:26:25.624553Z","iopub.status.idle":"2024-02-28T14:26:25.641281Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Create an empty dataframe to store training and testing accuracy for each<br>\nepoch.<br>","metadata":{}},{"cell_type":"code","source":"Accuracy_Percent <-data.frame(Training_percent = numeric(Epochs), Testing_percent = numeric(Epochs))","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:28.715231Z","iopub.execute_input":"2024-02-28T14:26:28.717183Z","iopub.status.idle":"2024-02-28T14:26:28.73308Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Fourier Feature Mapping for Gradient Descent\n### Sampling From a Gaussian Distribution With Mean 0 and Variance (sigma)^2\nRamdom sampled points are stored in B matrix.<br>","metadata":{}},{"cell_type":"code","source":"# Row size matrix X(data)\nXd_m_rows <-ncol(Row_Image_Matrix_training)\n\n# B Matrix = Sample from the Gaussian distribution with mean 0 and variance sigma^2\nB <- matrix(rnorm(Xd_m_rows * 1, mean = 0, sd = sigma), nrow = Xd_m_rows, ncol = 1)\n\n# Hf is harmonic frequencies (1 2 3 4...#number pixels)\nHf <- matrix(seq(1, Xd_m_rows), nrow = Xd_m_rows, ncol = 1)\n\n# B martrix for training data\nif (n < N_training) {\n#SGD and Mini Batch Gradient Descent\n# bind column n_iteration times\n\nB_training <- matrix(rep(B, n_iteration,), nrow = Xd_m_rows, ncol = n_iteration, byrow = FALSE)\n\nHf_training <- matrix(rep(Hf, n_iteration,), nrow = Xd_m_rows, ncol = n_iteration, byrow = FALSE)\n} else {\n#Batch Gradient Descent\n# bind column N_training times\nB_training <- matrix(rep(B, N_training,), nrow = Xd_m_rows, ncol = N_training, byrow = FALSE)  \n\nHf_training <- matrix(rep(Hf, N_training,), nrow = Xd_m_rows, ncol = N_training, byrow = FALSE)\n}\n\n######\n# B matrix for testing data\nB_testing <- matrix(rep(B, N_testing,), nrow = Xd_m_rows, ncol = N_testing, byrow = FALSE)\n\n# Hf matrix for testing data\nHf_testing <- matrix(rep(Hf, N_testing,), nrow = Xd_m_rows, ncol = N_testing, byrow = FALSE)\n######\n\n######\n# B matrix for data prediction\nB_pred <- matrix(rep(B, n_prediction,), nrow = Xd_m_rows, ncol = n_prediction, byrow = FALSE)\n\n# Hf matrix for data prediction\nHf_pred <- matrix(rep(Hf, n_prediction,), nrow = Xd_m_rows, ncol = n_prediction, byrow = FALSE)\n######\n\n# Hf*pi*B \nHf_pi_B_training <-Hf_training*pi*B_training\nHf_pi_B_testing <-Hf_testing*pi*B_testing\nHf_pi_B_pred <-Hf_pred*pi*B_pred","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:31.85323Z","iopub.execute_input":"2024-02-28T14:26:31.855038Z","iopub.status.idle":"2024-02-28T14:26:31.931905Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fourier Feature Mapping for Batch Gradient Descent (Training Data)","metadata":{}},{"cell_type":"code","source":"if (n == N_training) {\n# No mapping vs Fourier Feature Mapping\nswitch(NoMapping_vs_FourierFeatureMapping,\n    \"No mapping\" = {\n      X1_training <- Row_Image_Matrix_training %>% t()\n\n      X1_map_vs_no_map <- X1_training\n    },\n    \"Feature Mapping\" = {\n      # Xi = X1_training\n      # Batch Gradient Descent\n      X1_training <- Row_Image_Matrix_training %>% t()\n\n      Hf_pi_B_Xi <- Hf_pi_B_training * X1_training\n\n      # apply the cos to each element of the matrix\n      cos_element_wise <- cos(Hf_pi_B_Xi)\n\n      # apply the sin to each element of the matrix\n      sin_element_wise <- sin(Hf_pi_B_Xi)\n      ###############################################\n      # Create a vector of alternating ones and zeros\n      one_zero_V <- t(rep(c(1, 0), length.out = Xd_m_rows)) %>% as.matrix() \n\n      # Repeat and bind the vector into a matrix\n      one_zero_M <- matrix(rep(one_zero_V, N_training,), nrow = Xd_m_rows, ncol = N_training, byrow = FALSE)  \n\n      cos_matrix <- one_zero_M * cos_element_wise\n\n      # Create a vector of alternating zeros and ones\n      zero_one_V <- t(rep(c(0, 1), length.out = Xd_m_rows)) %>% as.matrix()\n\n      # Repeat and bind the vector into a matrix\n      zero_one_M <- matrix(rep(zero_one_V, N_training,), nrow = Xd_m_rows, ncol = N_training, byrow = FALSE)\n\n      sin_matrix <- zero_one_M * sin_element_wise\n\n      # Fourier Feature Mapping\n      gamma_Xi <- cos_matrix + sin_matrix\n\n      X1_map_vs_no_map <- gamma_Xi\n         })\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:35.815983Z","iopub.execute_input":"2024-02-28T14:26:35.817829Z","iopub.status.idle":"2024-02-28T14:26:35.833818Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Fourier Feature Mapping for SGD, Mini-Batch and Batch Gradient Descent (Testing Data)","metadata":{}},{"cell_type":"code","source":"# No mapping vs Fourier Feature Mapping\n#########################\n# No mapping vs Fourier Feature Mapping\nswitch(NoMapping_vs_FourierFeatureMapping,\n       \"No mapping\" = {\n    # Transpose to make each column an observation.\n    X1_testing <- Row_Image_Matrix_testing %>% t()\n\n    X1_map_vs_no_map_testing <-X1_testing\n       },\n       \"Feature Mapping\" = {\n    #Xi = X1_testing\n    X1_testing <-Row_Image_Matrix_testing %>% t()\n\n    Hf_pi_B_Xi_testing <-Hf_pi_B_testing * X1_testing\n\n    # apply the cos to each element of the matrix\n    cos_element_wise_testing <-cos(Hf_pi_B_Xi_testing)\n\n    # apply the sin to each element of the matrix\n    sin_element_wise_testing <-sin(Hf_pi_B_Xi_testing)\n    ###############################################\n    # Create a vector of alternating ones and zeros\n    one_zero_V_testing <- t(rep(c(1, 0), length.out = Xd_m_rows))  %>% as.matrix() \n\n    # Repeat and bind the vector into a matrix\n    one_zero_M_testing <- matrix(rep(one_zero_V_testing, N_testing,), nrow = Xd_m_rows, ncol = N_testing, byrow = FALSE)  \n\n    cos_matrix_testing <-one_zero_M_testing * cos_element_wise_testing\n\n    # Create a vector of alternating zeros and ones\n    zero_one_V_testing <- t(rep(c(0, 1), length.out = Xd_m_rows))  %>% as.matrix()\n\n    # Repeat and bind the vector into a matrix\n    zero_one_M_testing <- matrix(rep(zero_one_V_testing, N_testing,), nrow = Xd_m_rows, ncol = N_testing, byrow = FALSE)\n\n    sin_matrix_testing <-zero_one_M_testing * sin_element_wise_testing\n\n    # Fourier Feature Mapping\n    gamma_Xi_testing <- cos_matrix_testing + sin_matrix_testing\n\n    X1_map_vs_no_map_testing <-gamma_Xi_testing\n       })","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:39.894207Z","iopub.execute_input":"2024-02-28T14:26:39.896063Z","iopub.status.idle":"2024-02-28T14:26:39.943214Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Putting It All Together: Neural Network Code","metadata":{}},{"cell_type":"code","source":"# if n < N_training, then SGD and mini batch gradient descent\n# if n = N_training, then batch gradient descent\n#############################################################################################################\n# SGD AND MINI BATCH GRADIENT DESCENT\n#############################################################################################################\nif (n < N_training) {\n\nfor (epoch in 1:Epochs) {\n###############################################\n# Data Preprocessing for Training Data\n###############################################\n###############################################\n# Separate training\n###############################################\n# Randomly select n_iteration rows\n# replace = TRUE means that the same row can be selected more than once.\n# replace = FALSE means that the same row cannot be selected more than once.\nRandomly_selected_rows <-sample(nrow(Data_training_scaled), n_iteration, replace = FALSE)\n\n\n# Create a new matrix with the selected rows\nif (n == 1) {\n#SGD \nData_training <-Data_training_scaled[Randomly_selected_rows, ] %>% as.matrix()  %>% t()\n} else {\n#Mini Batch Gradient Descent\nData_training <-Data_training_scaled[Randomly_selected_rows, ] \n}\n\n###############################################\n# Let's separate the **y** column and the **image vector columns**.\n###############################################\n#Training data\nY_Labels_training <-Data_training[, 1]  %>% as.matrix()  %>% t()\n\nRow_Image_Matrix_training <-Data_training[, 2:ncol(Data_training)]  %>%  as.matrix()\n\n###############################################\n#One Hot Encoding Training Data\n###############################################\n# Initialize a list to store the basis vectors\nbasis_vectors_list_training <-list()\n\n# Loop over each column of the matrix\nfor (q in 1:n_iteration) {\n  # Get the label for the q-th column\n  label <- Y_Labels_training[1, q] %>% as.numeric()\n  \n  # Create a vector of zeros with length Q\n  basis_vectors_training <- rep(0, Q)\n  \n  # Set the (label+1)-th element to 1\n  basis_vectors_training[label + 1] <-1\n  \n  # Add the basis vector to the list\n  basis_vectors_list_training[[q]] <-basis_vectors_training %>% as.matrix()\n}\n\n# Convert the list of basis vectors to a matrix\nY_One_Hot_Encoding_training <- do.call(cbind, basis_vectors_list_training)\n  ###############################################\n  # Code for Training forward forward pass\n  ###############################################\n#########################\n# No mapping vs Fourier Feature Mapping\nswitch(NoMapping_vs_FourierFeatureMapping,\n       \"No mapping\" = {\nX1_training <- Row_Image_Matrix_training %>% t()\n\nX1_map_vs_no_map <-X1_training\n       },\n       \"Feature Mapping\" = {\n#Xi = X1_training\nif (n == 1) {\n  # SGD \n  X1_training <- Row_Image_Matrix_training\n} else {\n  # Mini Batch Gradient Descent\n  X1_training <- Row_Image_Matrix_training %>% t()\n}\n\nHf_pi_B_Xi <-Hf_pi_B_training * X1_training\n\n# apply the cos to each element of the matrix\ncos_element_wise <-cos(Hf_pi_B_Xi)\n\n# apply the sin to each element of the matrix\nsin_element_wise <-sin(Hf_pi_B_Xi)\n###############################################\n# Create a vector of alternating ones and zeros\none_zero_V <- t(rep(c(1, 0), length.out = Xd_m_rows))  %>% as.matrix() \n\n# Repeat and bind the vector into a matrix\none_zero_M <- matrix(rep(one_zero_V, n_iteration,), nrow = Xd_m_rows, ncol = n_iteration, byrow = FALSE)  \n\ncos_matrix <-one_zero_M * cos_element_wise\n\n# Create a vector of alternating zeros and ones\nzero_one_V <- t(rep(c(0, 1), length.out = Xd_m_rows))  %>% as.matrix()\n\n# Repeat and bind the vector into a matrix\nzero_one_M <- matrix(rep(zero_one_V, n_iteration,), nrow = Xd_m_rows, ncol = n_iteration, byrow = FALSE)\n\nsin_matrix <-zero_one_M * sin_element_wise\n\n# Fourier Feature Mapping\ngamma_Xi <- cos_matrix + sin_matrix\n\nX1_map_vs_no_map <-gamma_Xi\n       })\n#########################\n# Add bias row. Row of 1's\nif (n == 1) {\n  # SGD \nswitch(NoMapping_vs_FourierFeatureMapping,\n       \"No mapping\" = {\n  X1 <-rbind(t(X1_map_vs_no_map), c(1))\n       },\n       \"Feature Mapping\" = {\n  X1 <-rbind(X1_map_vs_no_map, rep(1, ncol(X1_map_vs_no_map)))\n      })\n\n} else {\n\n  # Mini Batch Gradient Descent\n  X1 <-rbind(X1_map_vs_no_map, rep(1, ncol(X1_map_vs_no_map)))\n}\n\nZ2 <- M1 %*% X1\n\n# LeakyReLU activation function\nif (n == 1) {\n  # SGD \n  LeakyReLU <- apply(Z2, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x)) %>% \n    as.matrix()\n} else {\n  # Mini Batch Gradient Descent\n  LeakyReLU <- t(apply(Z2, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n    as.matrix()\n}\n\nX2 <- rbind(LeakyReLU, 1) %>% \n  as.matrix()\n\n###############################################\n# For one and two hidden layers\nif (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\nZ_out <- M2 %*% X2\n\n} else {\n###############\n# When using Two Hidden Layers\n###############\nZ3 <- M2 %*% X2\n\n# LeakyReLU activation function\nif (n == 1) {\n  # SGD \n  LeakyReLU2 <- apply(Z3, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x)) %>% \n    as.matrix()\n} else {\n  # Mini Batch Gradient Descent\n  LeakyReLU2 <- t(apply(Z3, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n    as.matrix()\n}\n\nX3 <- rbind(LeakyReLU2, 1) %>% \n  as.matrix()\n\nZ_out <- M3 %*% X3\n}\n###############################################\n# Define Softmax(Max)\nsoftmax_MAX <- function(z) {\n  # zi-max(z)\n  zi_max <-z - max(z)\n  # e^(zi-max(z))\n  exp_zi_max <-exp(zi_max)\n  # e^(zi-max(z)-log(sum(e^(zj-max(z)))\n  exp(zi_max - log(sum(exp_zi_max)))\n}\n\n# note that:\n# apply(Z_out, 1 ----means its row wise\n# apply(Z_out, 2 ----means its column wise\n# Apply the softmax function to each column\nX_out <- apply(Z_out, 2, softmax_MAX)\n###############################################\n# Code for Testing forward forward pass\n###############################################\n# Add bias row. Row of 1's\nX1_test <-rbind(X1_map_vs_no_map_testing, rep(1, ncol(X1_map_vs_no_map_testing)))\n\nZ2_testing <- M1 %*% X1_test\n\nLeakyReLU_testing <- t(apply(Z2_testing, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n    as.matrix()\n\nX2_testing <- rbind(LeakyReLU_testing, 1) %>% \n  as.matrix()\n###############################################\n# For one and two hidden layers\nif (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\nZ_out_testing <- M2 %*% X2_testing\n\n} else {\n###############\n# When using Two Hidden Layers\n###############\nZ3_testing <- M2 %*% X2_testing\n\nLeakyReLU2_testing <- t(apply(Z3_testing, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n    as.matrix()\n\nX3_testing <- rbind(LeakyReLU2_testing, 1) %>% \n  as.matrix()\n\nZ_out_testing <- M3 %*% X3_testing\n}\n\n# Apply the softmax function to each column\nX_out_testing <- apply(Z_out_testing, 2, softmax_MAX)\n\n  ###############################################\n  # Code for backpropagation training\n  ###############################################\nif (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\n  ###############\n  # DC/DM2\n  ###############\n  dc_dX_out_t_times_dX_out_dZ3_out_t <- (X_out - Y_One_Hot_Encoding_training) %>% as.matrix()\n\n  dZ3_out_dM2 <- t(X2)\n\n  # dC/dM2 = [(dC/dX_out)^t *(dX_out/dZ3_out)^t]^t * dZ3_out/dM2\n  dC_dM2 <- dc_dX_out_t_times_dX_out_dZ3_out_t %*% dZ3_out_dM2 %>% as.matrix()\n\n  ###############\n  # DC/DM1\n  ###############\n  # (dC/dX_out)^t *(dX_out/dZ3_out)^t\n  dc_dX_out_t_times_dX_out_dZ3_out_t_t <- t(dc_dX_out_t_times_dX_out_dZ3_out_t)\n\n  dZ3_out_dX2 <- M2[, -ncol(M2)] %>% as.matrix()\n\n  # dX2/dZ2 (element wise)\n  if (n == 1) {\n    # SGD \n    dX2_dZ2_element_wise <- apply(X2, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha)) %>% as.matrix()\n  } else {\n    # Mini Batch Gradient \n    dX2_dZ2_element_wise <- t(apply(X2, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha))) %>% as.matrix()\n  }\n\n  dX2_dZ2 <- dX2_dZ2_element_wise[-nrow(dX2_dZ2_element_wise),] %>% \n    as.matrix()\n\n  dZ2_dM1 <- t(X1)\n\n  dC_dM1 <- ((t(dc_dX_out_t_times_dX_out_dZ3_out_t_t %*% dZ3_out_dX2)) * dX2_dZ2) %*% dZ2_dM1\n} else {\n###############\n# When using Two Hidden Layers\n###############\n  ###############\n  # DC/DM3\n  ###############\n  dc_dZ_out_t <-(X_out - Y_One_Hot_Encoding_training) %>% as.matrix()\n\n  dZ_out_dM3 <-t(X3)\n\n  dC_dM3 <-dc_dZ_out_t %*% dZ_out_dM3 %>% as.matrix()\n\n  ###############\n  # DC/DM2\n  ###############\n  dc_dZ_out <- t(dc_dZ_out_t)\n\n  dZ4_dX3 <- M3[, -ncol(M3)] %>% as.matrix()\n\n  # dX3/dZ3 (element wise)\n  if (n == 1) {\n    # SGD \n    dX3_dZ3_element_wise <- apply(X3, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha)) %>% as.matrix()\n  } else {\n    # Mini Batch Gradient \n    dX3_dZ3_element_wise <- t(apply(X3, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha))) %>% as.matrix()\n  }\n\n  dX3_dZ3 <- dX3_dZ3_element_wise[-nrow(dX3_dZ3_element_wise),] %>% \n    as.matrix()\n\n  dZ3_dM2 <- t(X2)\n\n  dC_dZ3 <-(t(dc_dZ_out %*% dZ4_dX3)) * dX3_dZ3\n\n  dC_dM2 <-dC_dZ3 %*% dZ3_dM2\n  ###############\n  # DC/DM1\n  ###############\n  dC_dZ3_t <- t(dC_dZ3)\n\n  dZ3_dX2 <- M2[, -ncol(M2)] %>% as.matrix()\n\n  # dX2/dZ2 (element wise)\n  if (n == 1) {\n    # SGD \n    dX2_dZ2_element_wise <- apply(X2, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha)) %>% as.matrix()\n  } else {\n    # Mini Batch Gradient \n    dX2_dZ2_element_wise <- t(apply(X2, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha))) %>% as.matrix()\n  }\n\n  dX2_dZ2 <- dX2_dZ2_element_wise[-nrow(dX2_dZ2_element_wise),] %>% \n    as.matrix()\n\n  dZ2_dM1 <- t(X1)\n\n  dC_dZ2 <-(t(dC_dZ3_t %*% dZ3_dX2)) * dX2_dZ2\n\n  dC_dM1 <-dC_dZ2 %*% dZ2_dM1\n}\n\n##############################################################\n  # Gradient Descent\n#############################################################\n# note that in SGD and mini-batch, Epochs = Epoch*number_iterations_epoch\n# Update weights and biases (based on backpropagation)\nif (num_hidden_layers < 2) {\n###############################################\n# When using One Hidden Layer\n###############################################\nswitch(gradient_descent_algorithm,\n       \"constant\" = {\n###############\n# # When using constant learning rate\n###############\nLearning_Rate <-Alpha_ONE\n\nfor (i in 1:Epochs){\nM2 <-M2 - (Learning_Rate * dC_dM2)\nM1 <-M1 - (Learning_Rate * dC_dM1)\n}\n       },\n       \"decaying\" = {\n###############\n# When using decaying learning rate\n###############\nfor (i in 1:Epochs){\n  # Update the learning rate for each epoch/iteration\nLearning_Rate <-Alpha_ONE * (1/i)\n\nM2 <-M2 - (Learning_Rate * dC_dM2)\nM1 <-M1 - (Learning_Rate * dC_dM1)\n}\n       },\n       \"adam\" = {\n###############\n# When using Adam optimizer\n###############\nfor (i in 1:Epochs){\n#####\n# M2 \n#####\n# 1st moment\nv1_M2 <-v1 # Initialize v1=0 at t=1\nv1_prev_M2 <- v1_M2\nv1_M2 <- (Beta1 * v1_M2) + ((1 - Beta1) * dC_dM2)\n\n# 2nd moment\nv2_M2 <-v2 # Initialize v2=0 at t=1\nv2_prev_M2 <- v2_M2\nv2_M2 <- (Beta2 * v2_M2) + ((1 - Beta2) * (dC_dM2^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M2 <- v1_prev_M2\n  v2_M2 <- v2_prev_M2\n}\n\n# Bias corrected 1st moment\nv1_hat_M2 <- v1_M2 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M2 <- v2_M2 / (1 - (Beta2^i))\n\n# Update M2 using the bias-corrected moments and learning rate\nM2 <- M2 - (Alpha_ONE * (v1_hat_M2 / (sqrt(v2_hat_M2) + Epsilon)))\n#####\n# M1\n#####\n# 1st moment\nv1_M1 <-v1 # Initialize v1=0 at t=1\nv1_prev_M1 <- v1_M1 \nv1_M1 <- (Beta1 * v1_M1) + ((1 - Beta1) * dC_dM1)\n\n# 2nd moment\nv2_M1 <-v2 # Initialize v2=0 at t=1\nv2_prev_M1 <- v2_M1\nv2_M1 <- (Beta2 * v2_M1) + ((1 - Beta2) * (dC_dM1^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M1 <- v1_prev_M1\n  v2_M1 <- v2_prev_M1\n}\n\n# Bias corrected 1st moment\nv1_hat_M1 <- v1_M1 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M1 <- v2_M1 / (1 - (Beta2^i))\n\n# Update M1 using the bias-corrected moments and learning rate\nM1 <- M1 - (Alpha_ONE * (v1_hat_M1 / (sqrt(v2_hat_M1) + Epsilon)))\n\n}\n       }\n)\n  #Store M2 for each epoch\nM2_list[[epoch]] <-M2\n  #Store M1 for each epoch\nM1_list[[epoch]] <-M1\n\n} else {\n###############################################\n# When using Two Hidden Layers\n###############################################\nswitch(gradient_descent_algorithm,\n       \"constant\" = {\n###############\n# # When using constant learning rate\n###############\nLearning_Rate <-Alpha_ONE\n\nfor (i in 1:Epochs){\nM3 <-M3 - (Learning_Rate * dC_dM3)\nM2 <-M2 - (Learning_Rate * dC_dM2)\nM1 <-M1 - (Learning_Rate * dC_dM1)\n}\n       },\n       \"decaying\" = {\n###############\n# When using decaying learning rate\n###############\nfor (i in 1:Epochs){\n  # Update the learning rate for each epoch/iteration\nLearning_Rate <-Alpha_ONE * (1/i)\n\nM3 <-M3 - (Learning_Rate * dC_dM3)\nM2 <-M2 - (Learning_Rate * dC_dM2)\nM1 <-M1 - (Learning_Rate * dC_dM1)\n}\n       },\n       \"adam\" = {\n###############\n# When using Adam optimizer\n###############\nfor (i in 1:Epochs){\n#####\n# M3\n#####\n\n# 1st moment\nv1_M3 <-v1 # Initialize v1=0 at t=1\nv1_prev_M3 <- v1_M3\nv1_M3 <- (Beta1 * v1_M3) + ((1 - Beta1) * dC_dM3)\n\n# 2nd moment\nv2_M3 <-v2 # Initialize v2=0 at t=1\nv2_prev_M3 <- v2_M3\nv2_M3 <- (Beta2 * v2_M3) + ((1 - Beta2) * (dC_dM3^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M3 <- v1_prev_M3\n  v2_M3 <- v2_prev_M3\n}\n\n# Bias corrected 1st moment\nv1_hat_M3 <- v1_M3 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M3 <- v2_M3 / (1 - (Beta2^i))\n\n# Update M3 using the bias-corrected moments and learning rate\nM3 <- M3 - (Alpha_ONE * (v1_hat_M3 / (sqrt(v2_hat_M3) + Epsilon)))\n#####\n# M2\n#####\n# 1st moment\nv1_M2 <-v1 # Initialize v1=0 at t=1\nv1_prev_M2 <- v1_M2\nv1_M2 <- (Beta1 * v1_M2) + ((1 - Beta1) * dC_dM2)\n\n# 2nd moment\nv2_M2 <-v2 # Initialize v2=0 at t=1\nv2_prev_M2 <- v2_M2\nv2_M2 <- (Beta2 * v2_M2) + ((1 - Beta2) * (dC_dM2^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M2 <- v1_prev_M2\n  v2_M2 <- v2_prev_M2\n}\n\n# Bias corrected 1st moment\nv1_hat_M2 <- v1_M2 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M2 <- v2_M2 / (1 - (Beta2^i))\n\n# Update M2 using the bias-corrected moments and learning rate\nM2 <- M2 - (Alpha_ONE * (v1_hat_M2 / (sqrt(v2_hat_M2) + Epsilon)))\n#####\n# M1\n#####\n# 1st moment\nv1_M1 <-v1 # Initialize v1=0 at t=1\nv1_prev_M1 <- v1_M1\nv1_M1 <- (Beta1 * v1_M1) + ((1 - Beta1) * dC_dM1)\n\n# 2nd moment\nv2_M1 <-v2 # Initialize v2=0 at t=1\nv2_prev_M1 <- v2_M1\nv2_M1 <- (Beta2 * v2_M1) + ((1 - Beta2) * (dC_dM1^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M1 <- v1_prev_M1\n  v2_M1 <- v2_prev_M1\n}\n\n# Bias corrected 1st moment\nv1_hat_M1 <- v1_M1 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M1 <- v2_M1 / (1 - (Beta2^i))\n\n# Update M1 using the bias-corrected moments and learning rate\nM1 <- M1 - (Alpha_ONE * (v1_hat_M1 / (sqrt(v2_hat_M1) + Epsilon)))\n\n}\n       }\n)\n\n  #Store M3 for each epoch\nM3_list[[epoch]] <-M3\n  #Store M2 for each epoch\nM2_list[[epoch]] <-M2\n  #Store M1 for each epoch\nM1_list[[epoch]] <-M1\n\n}\n  ###############################################\n  # Compute Mean Categorical Cross Entropy Loss and store it in the CCEntropy_Loss dataframe\n  ###############################################\n  ###############\n  # Mean Categorical Cross Entropy Loss Training\n  ###############\n  #Categorical Cross Entropy Loss\n  Cost_training <- -Y_One_Hot_Encoding_training * log(X_out) \n\n  # Sums up the CCE Loss for each observation\n  Cost_training <- colSums(Cost_training)\n\n  #Stores mean CCE Loss X_out for each epoch\n  CCEntropy_Loss$CCEL_x_out[epoch] <-round(mean(Cost_training), 2)\n\n  #Stores iteration number(it says [epoch] but its actually iteration number)\n  CCEntropy_Loss$iteration[epoch] <-epoch\n\n  #Stores epoch number\n  CCEntropy_Loss$epoch[epoch] <-round(CCEntropy_Loss$iteration[epoch]/number_iterations_epoch, 2)\n  ###############\n  # Mean Categorical Cross Entropy Loss Testing\n  ###############\n  #Categorical Cross Entropy Loss\n  Cost_testing <- -Y_One_Hot_Encoding_testing * log(X_out_testing)  \n\n  # Sums up the CCE Loss for each observation  \n  Cost_testing <- colSums(Cost_testing)\n\n  #Stores mean CCE Loss X_out (testing) for each epoch\n  CCEntropy_Loss$CCEL_testing_x_out[epoch] <-round(mean(Cost_testing), 2)\n  ###############################################\n  # Compute Accuracy for each epoch\n  ###############################################\n  ###############\n  #Accuracy Training\n  ###############\n  # Find the highest probability for each observation in X_out\n  X_out_highest <- apply(X_out, 2, max)\n\n  X_out_hadamard_Y_training <-X_out * Y_One_Hot_Encoding_training\n\n  # Create a vector that contains the highest value for each column\n  X_out_hadamard_Y_v_training <- apply(X_out_hadamard_Y_training, 2, max)\n\n  # Subtract the two vectors\n  difference_training <- X_out_highest - X_out_hadamard_Y_v_training\n\n  # Count the number of zeros\n  count_zeros_training <- sum(difference_training == 0)\n\n  # Accuaracy = (number of zeros * 100) / number of observations, round to 2 decimal places\n  accuracy_percent_training <- round((count_zeros_training * 100) / N_training, 2)\n\n  #Stores training accuracy percentage for each epoch\n  Accuracy_Percent$Training_percent[epoch] <-accuracy_percent_training\n###############\n#Accuracy Testing\n###############\n# Find the highest probability for each observation in X_out_testing\nX_out_testing_highest <- apply(X_out_testing, 2, max)\n\nX_out_testing_hadamard_Y_testing <-X_out_testing * Y_One_Hot_Encoding_testing\n\n# Create a vector that contains the highest value for each column\nX_out_testing_hadamard_Y_v_testing <- apply(X_out_testing_hadamard_Y_testing, 2, max)\n\n# Subtract the two vectors\ndifference_testing <- X_out_testing_highest - X_out_testing_hadamard_Y_v_testing\n\n# Count the number of zeros\ncount_zeros_testing <- sum(difference_testing == 0)\n\n# Accuaracy = (number of zeros * 100) / number of observations, round to 2 decimal places\naccuracy_percent_testing <- round((count_zeros_testing * 100) / N_testing, 2)\n\n#Stores testing accuracy percentage for each epoch\nAccuracy_Percent$Testing_percent[epoch] <-accuracy_percent_testing\n \n###############################################\n  # Comment out #cat() to prevent results from being printed out on console\n  #cat(\"iteration: \", epoch, \"\\n\",\n    #\"epoch: \", CCEntropy_Loss$epoch[epoch], \"\\n\\n\",\n    #\"Training Mean CCE Loss: \", CCEntropy_Loss$CCEL_x_out[epoch], \"\\n\",\n    #\"Testing Mean CCE Loss: \", CCEntropy_Loss$CCEL_testing_x_out[epoch], \"\\n\\n\",\n    #\"Training Accuracy Percent: \", Accuracy_Percent$Training_percent[epoch], \"%\\n\",\n    #\"Testing Accuracy Percent: \", Accuracy_Percent$Testing_percent[epoch], \"%\\n\\n\")\n\n}\n#############################################################################################################\n#BATCH GRADIENT DESCENT\n#############################################################################################################\n} else {\nfor (epoch in 1:Epochs) {\n  ###############################################\n  # Code for Training forward forward pass\n  ###############################################\n# Batch Gradient Descent\nX1 <-rbind(X1_map_vs_no_map, rep(1, ncol(X1_map_vs_no_map)))\n\nZ2 <- M1 %*% X1\n\nLeakyReLU <- t(apply(Z2, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n  as.matrix()\n\nX2 <- rbind(LeakyReLU, 1) %>% \n  as.matrix()\n\n###############################################\n# For one and two hidden layers\nif (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\nZ_out <- M2 %*% X2\n\n} else {\n###############\n# When using Two Hidden Layers\n###############\nZ3 <- M2 %*% X2\n\n# LeakyReLU activation function\nif (n == 1) {\n  # SGD \n  LeakyReLU2 <- apply(Z3, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x)) %>% \n    as.matrix()\n} else {\n  # Mini Batch Gradient Descent\n  LeakyReLU2 <- t(apply(Z3, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n    as.matrix()\n}\n\nX3 <- rbind(LeakyReLU2, 1) %>% \n  as.matrix()\n\nZ_out <- M3 %*% X3\n}\n###############################################\n\n# Define Softmax(Max)\nsoftmax_MAX <- function(z) {\n  # zi-max(z)\n  zi_max <- z - max(z)\n  # e^(zi-max(z))\n  exp_zi_max <- exp(zi_max)\n  # e^(zi-max(z)-log(sum(e^(zj-max(z)))\n  exp(zi_max - log(sum(exp_zi_max)))\n}\n\n# note that:\n# apply(Z_out, 1 ----means its row wise\n# apply(Z_out, 2 ----means its column wise\n# Apply the softmax function to each column\nX_out <- apply(Z_out, 2, softmax_MAX)\n\n###############################################\n# Code for Testing forward forward pass\n###############################################\n# Add bias row. Row of 1's\nX1_test <-rbind(X1_map_vs_no_map_testing, rep(1, ncol(X1_map_vs_no_map_testing)))\n\nZ2_testing <- M1 %*% X1_test\n\nLeakyReLU_testing <- t(apply(Z2_testing, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n    as.matrix()\n\nX2_testing <- rbind(LeakyReLU_testing, 1) %>% \n  as.matrix()\n###############################################\n# For one and two hidden layers\nif (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\nZ_out_testing <- M2 %*% X2_testing\n\n} else {\n###############\n# When using Two Hidden Layers\n###############\nZ3_testing <- M2 %*% X2_testing\n\nLeakyReLU2_testing <- t(apply(Z3_testing, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n    as.matrix()\n\nX3_testing <- rbind(LeakyReLU2_testing, 1) %>% \n  as.matrix()\n\nZ_out_testing <- M3 %*% X3_testing\n}\n\n# Apply the softmax function to each column\nX_out_testing <- apply(Z_out_testing, 2, softmax_MAX)\n\n  ###############################################\n  # Code for backpropagation training\n  ###############################################\n if (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\n  ###############\n  # DC/DM2\n  ###############\n  dc_dX_out_t_times_dX_out_dZ3_out_t <- (X_out - Y_One_Hot_Encoding_training) %>% as.matrix()\n\n  dZ3_out_dM2 <- t(X2)\n\n  # dC/dM2 = [(dC/dX_out)^t *(dX_out/dZ3_out)^t]^t * dZ3_out/dM2\n  dC_dM2 <- dc_dX_out_t_times_dX_out_dZ3_out_t %*% dZ3_out_dM2 %>% as.matrix()\n\n  ###############\n  # DC/DM1\n  ###############\n  # (dC/dX_out)^t *(dX_out/dZ3_out)^t\n  dc_dX_out_t_times_dX_out_dZ3_out_t_t <- t(dc_dX_out_t_times_dX_out_dZ3_out_t)\n\n  dZ3_out_dX2 <- M2[, -ncol(M2)] %>% as.matrix()\n\n  # dX2/dZ2 (element wise)\n  if (n == 1) {\n    # SGD \n    dX2_dZ2_element_wise <- apply(X2, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha)) %>% as.matrix()\n  } else {\n    # Mini Batch Gradient \n    dX2_dZ2_element_wise <- t(apply(X2, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha))) %>% as.matrix()\n  }\n\n  dX2_dZ2 <- dX2_dZ2_element_wise[-nrow(dX2_dZ2_element_wise),] %>% \n    as.matrix()\n\n  dZ2_dM1 <- t(X1)\n\n  dC_dM1 <- ((t(dc_dX_out_t_times_dX_out_dZ3_out_t_t %*% dZ3_out_dX2)) * dX2_dZ2) %*% dZ2_dM1\n} else {\n###############\n# When using Two Hidden Layers\n###############\n  ###############\n  # DC/DM3\n  ###############\n  dc_dZ_out_t <-(X_out - Y_One_Hot_Encoding_training) %>% as.matrix()\n\n  dZ_out_dM3 <-t(X3)\n\n  dC_dM3 <-dc_dZ_out_t %*% dZ_out_dM3 %>% as.matrix()\n\n  ###############\n  # DC/DM2\n  ###############\n  dc_dZ_out <- t(dc_dZ_out_t)\n\n  dZ4_dX3 <- M3[, -ncol(M3)] %>% as.matrix()\n\n  # dX3/dZ3 (element wise)\n  if (n == 1) {\n    # SGD \n    dX3_dZ3_element_wise <- apply(X3, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha)) %>% as.matrix()\n  } else {\n    # Mini Batch Gradient \n    dX3_dZ3_element_wise <- t(apply(X3, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha))) %>% as.matrix()\n  }\n\n  dX3_dZ3 <- dX3_dZ3_element_wise[-nrow(dX3_dZ3_element_wise),] %>% \n    as.matrix()\n\n  dZ3_dM2 <- t(X2)\n\n  dC_dZ3 <-(t(dc_dZ_out %*% dZ4_dX3)) * dX3_dZ3\n\n  dC_dM2 <-dC_dZ3 %*% dZ3_dM2\n  ###############\n  # DC/DM1\n  ###############\n  dC_dZ3_t <- t(dC_dZ3)\n\n  dZ3_dX2 <- M2[, -ncol(M2)] %>% as.matrix()\n\n  # dX2/dZ2 (element wise)\n  if (n == 1) {\n    # SGD \n    dX2_dZ2_element_wise <- apply(X2, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha)) %>% as.matrix()\n  } else {\n    # Mini Batch Gradient \n    dX2_dZ2_element_wise <- t(apply(X2, 1, function(x) ifelse(x >= 0, 1, LeakyReLU_alpha))) %>% as.matrix()\n  }\n\n  dX2_dZ2 <- dX2_dZ2_element_wise[-nrow(dX2_dZ2_element_wise),] %>% \n    as.matrix()\n\n  dZ2_dM1 <- t(X1)\n\n  dC_dZ2 <-(t(dC_dZ3_t %*% dZ3_dX2)) * dX2_dZ2\n\n  dC_dM1 <-dC_dZ2 %*% dZ2_dM1\n}\n\n##############################################################\n  # Gradient Descent\n#############################################################\n# note that in SGD and minibatch Epochs = Epoch*number_iterations_epoch\n# Update weights and biases (based on backpropagation)\n  \nif (num_hidden_layers < 2) {\n###############################################\n# When using One Hidden Layer\n###############################################\nswitch(gradient_descent_algorithm,\n       \"constant\" = {\n###############\n# # When using constant learning rate\n###############\nLearning_Rate <-Alpha_ONE\n\nfor (i in 1:Epochs){\nM2 <-M2 - (Learning_Rate * dC_dM2)\nM1 <-M1 - (Learning_Rate * dC_dM1)\n}\n       },\n       \"decaying\" = {\n###############\n# When using decaying learning rate\n###############\nfor (i in 1:Epochs){\n  # Update the learning rate for each epoch/iteration\nLearning_Rate <-Alpha_ONE * (1/i)\n\nM2 <-M2 - (Learning_Rate * dC_dM2)\nM1 <-M1 - (Learning_Rate * dC_dM1)\n}\n       },\n       \"adam\" = {\n###############\n# When using Adam optimizer\n###############\n###############\n# When using Adam optimizer\n###############\nfor (i in 1:Epochs){\n#####\n# M2 \n#####\n# 1st moment\nv1_M2 <-v1 # Initialize v1=0 at t=1\nv1_prev_M2 <- v1_M2\nv1_M2 <- (Beta1 * v1_M2) + ((1 - Beta1) * dC_dM2)\n\n# 2nd moment\nv2_M2 <-v2 # Initialize v2=0 at t=1\nv2_prev_M2 <- v2_M2\nv2_M2 <- (Beta2 * v2_M2) + ((1 - Beta2) * (dC_dM2^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M2 <- v1_prev_M2\n  v2_M2 <- v2_prev_M2\n}\n\n# Bias corrected 1st moment\nv1_hat_M2 <- v1_M2 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M2 <- v2_M2 / (1 - (Beta2^i))\n\n# Update M2 using the bias-corrected moments and learning rate\nM2 <- M2 - (Alpha_ONE * (v1_hat_M2 / (sqrt(v2_hat_M2) + Epsilon)))\n#####\n# M1\n#####\n# 1st moment\nv1_M1 <-v1 # Initialize v1=0 at t=1\nv1_prev_M1 <- v1_M1 \nv1_M1 <- (Beta1 * v1_M1) + ((1 - Beta1) * dC_dM1)\n\n# 2nd moment\nv2_M1 <-v2 # Initialize v2=0 at t=1\nv2_prev_M1 <- v2_M1\nv2_M1 <- (Beta2 * v2_M1) + ((1 - Beta2) * (dC_dM1^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M1 <- v1_prev_M1\n  v2_M1 <- v2_prev_M1\n}\n\n# Bias corrected 1st moment\nv1_hat_M1 <- v1_M1 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M1 <- v2_M1 / (1 - (Beta2^i))\n\n# Update M1 using the bias-corrected moments and learning rate\nM1 <- M1 - (Alpha_ONE * (v1_hat_M1 / (sqrt(v2_hat_M1) + Epsilon)))\n\n} \n       }\n)\n\n  #Store M2 for each epoch\nM2_list[[epoch]] <-M2\n  #Store M1 for each epoch\nM1_list[[epoch]] <-M1\n\n} else {\n###############################################\n# When using Two Hidden Layers\n###############################################\nswitch(gradient_descent_algorithm,\n       \"constant\" = {\n###############\n# # When using constant learning rate\n###############\nLearning_Rate <-Alpha_ONE\n\nfor (i in 1:Epochs){\nM3 <-M3 - (Learning_Rate * dC_dM3)\nM2 <-M2 - (Learning_Rate * dC_dM2)\nM1 <-M1 - (Learning_Rate * dC_dM1)\n}\n       },\n       \"decaying\" = {\n###############\n# When using decaying learning rate\n###############\nfor (i in 1:Epochs){\n  # Update the learning rate for each epoch/iteration\nLearning_Rate <-Alpha_ONE * (1/i)\n\nM3 <-M3 - (Learning_Rate * dC_dM3)\nM2 <-M2 - (Learning_Rate * dC_dM2)\nM1 <-M1 - (Learning_Rate * dC_dM1)\n}\n       },\n       \"adam\" = {\n###############\n# When using Adam optimizer\n###############\n###############\n# When using Adam optimizer\n###############\nfor (i in 1:Epochs){\n#####\n# M3\n#####\n\n# 1st moment\nv1_M3 <-v1 # Initialize v1=0 at t=1\nv1_prev_M3 <- v1_M3\nv1_M3 <- (Beta1 * v1_M3) + ((1 - Beta1) * dC_dM3)\n\n# 2nd moment\nv2_M3 <-v2 # Initialize v2=0 at t=1\nv2_prev_M3 <- v2_M3\nv2_M3 <- (Beta2 * v2_M3) + ((1 - Beta2) * (dC_dM3^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M3 <- v1_prev_M3\n  v2_M3 <- v2_prev_M3\n}\n\n# Bias corrected 1st moment\nv1_hat_M3 <- v1_M3 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M3 <- v2_M3 / (1 - (Beta2^i))\n\n# Update M3 using the bias-corrected moments and learning rate\nM3 <- M3 - (Alpha_ONE * (v1_hat_M3 / (sqrt(v2_hat_M3) + Epsilon)))\n#####\n# M2\n#####\n# 1st moment\nv1_M2 <-v1 # Initialize v1=0 at t=1\nv1_prev_M2 <- v1_M2\nv1_M2 <- (Beta1 * v1_M2) + ((1 - Beta1) * dC_dM2)\n\n# 2nd moment\nv2_M2 <-v2 # Initialize v2=0 at t=1\nv2_prev_M2 <- v2_M2\nv2_M2 <- (Beta2 * v2_M2) + ((1 - Beta2) * (dC_dM2^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M2 <- v1_prev_M2\n  v2_M2 <- v2_prev_M2\n}\n\n# Bias corrected 1st moment\nv1_hat_M2 <- v1_M2 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M2 <- v2_M2 / (1 - (Beta2^i))\n\n# Update M2 using the bias-corrected moments and learning rate\nM2 <- M2 - (Alpha_ONE * (v1_hat_M2 / (sqrt(v2_hat_M2) + Epsilon)))\n#####\n# M1\n#####\n# 1st moment\nv1_M1 <-v1 # Initialize v1=0 at t=1\nv1_prev_M1 <- v1_M1\nv1_M1 <- (Beta1 * v1_M1) + ((1 - Beta1) * dC_dM1)\n\n# 2nd moment\nv2_M1 <-v2 # Initialize v2=0 at t=1\nv2_prev_M1 <- v2_M1\nv2_M1 <- (Beta2 * v2_M1) + ((1 - Beta2) * (dC_dM1^2))\n\n# Stores the previous values of v1 and v2 starting at i=2\nif (i > 1) {\n  v1_M1 <- v1_prev_M1\n  v2_M1 <- v2_prev_M1\n}\n\n# Bias corrected 1st moment\nv1_hat_M1 <- v1_M1 / (1 - (Beta1^i))\n\n# Bias corrected 2nd moment\nv2_hat_M1 <- v2_M1 / (1 - (Beta2^i))\n\n# Update M1 using the bias-corrected moments and learning rate\nM1 <- M1 - (Alpha_ONE * (v1_hat_M1 / (sqrt(v2_hat_M1) + Epsilon)))\n}\n       }\n)\n\n  #Store M3 for each epoch\nM3_list[[epoch]] <-M3\n  #Store M2 for each epoch\nM2_list[[epoch]] <-M2\n  #Store M1 for each epoch\nM1_list[[epoch]] <-M1\n\n}\n  ###############################################\n  # Compute Mean Categorical Cross Entropy Loss and store it in the CCEntropy_Loss dataframe\n  ###############################################\n###############\n# Mean Categorical Cross Entropy Loss Training\n###############\n# Catagorical Cross Entropy Loss\nCost_training <- -Y_One_Hot_Encoding_training * log(X_out)\n\n# Sums up the CCE Loss for each observation\nCost_training <- colSums(Cost_training)\n\n# Stores mean CCE Loss X_out for each epoch\nCCEntropy_Loss$CCEL_x_out[epoch] <- round(mean(Cost_training), 2)\n\n# Stores epoch number for each epoch\nCCEntropy_Loss$epoch[epoch] <- epoch\n###############\n# Mean Categorical Cross Entropy Loss Testing\n###############\n# Catagorical Cross Entropy Loss\nCost_testing <- -Y_One_Hot_Encoding_testing * log(X_out_testing) \n\n# Sums up the CCE Loss for each observation\nCost_testing <- colSums(Cost_testing)\n\n# Stores mean CCE Loss X_out (testing) for each epoch\nCCEntropy_Loss$CCEL_testing_x_out[epoch] <- round(mean(Cost_testing), 2)\n  ###############################################\n  # Compute Accuracy for each epoch\n  ###############################################\n###############\n#Accuracy Training\n###############\n# Find the highest probability for each observation in X_out\nX_out_highest <- apply(X_out, 2, max)\n\nX_out_hadamard_Y_training <- X_out * Y_One_Hot_Encoding_training\n\n# Create a vector that contains the highest value for each column\nX_out_hadamard_Y_v_training <- apply(X_out_hadamard_Y_training, 2, max)\n\n# Subtract the two vectors\ndifference_training <- X_out_highest - X_out_hadamard_Y_v_training\n\n# Count the number of zeros\ncount_zeros_training <- sum(difference_training == 0)\n\n# Accuracy = (number of zeros * 100) / number of observations, round to 2 decimal places\naccuracy_percent_training <- round((count_zeros_training * 100) / N_training, 2)\n\n# Stores training accuracy percentage for each epoch\nAccuracy_Percent$Training_percent[epoch] <- accuracy_percent_training\n###############\n  #Accuracy Testing\n###############\n# Find the highest probability for each observation in X_out_testing\nX_out_testing_highest <- apply(X_out_testing, 2, max)\n\nX_out_testing_hadamard_Y_testing <- X_out_testing * Y_One_Hot_Encoding_testing\n\n# Create a vector that contains the highest value for each column\nX_out_testing_hadamard_Y_v_testing <- apply(X_out_testing_hadamard_Y_testing, 2, max)\n\n# Subtract the two vectors\ndifference_testing <- X_out_testing_highest - X_out_testing_hadamard_Y_v_testing\n\n# Count the number of zeros\ncount_zeros_testing <- sum(difference_testing == 0)\n\n# Accuracy = (number of zeros * 100) / number of observations, round to 2 decimal places\naccuracy_percent_testing <- round((count_zeros_testing * 100) / N_testing, 2)\n\n# Stores testing accuracy percentage for each epoch\nAccuracy_Percent$Testing_percent[epoch] <- accuracy_percent_testing\n###############################################\n  # Comment out #cat() will make results not being printed out on console\n  #cat(\"Epoch: \", epoch, \"\\n\",\n    #\"Training Mean CCE Loss: \", CCEntropy_Loss$CCEL_x_out[epoch], \"\\n\",\n    #\"Testing Mean CCE Loss: \", CCEntropy_Loss$CCEL_testing_x_out[epoch], \"\\n\\n\",\n    #\"Training Accuracy Percent: \", Accuracy_Percent$Training_percent[epoch], \"%\\n\",\n    #\"Testing Accuracy Percent: \", Accuracy_Percent$Testing_percent[epoch], \"%\\n\\n\")\n}\n\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:26:45.001284Z","iopub.execute_input":"2024-02-28T14:26:45.003549Z","iopub.status.idle":"2024-02-28T14:30:56.482781Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Minimum value for mean categorical cross entropy loss.<br>\nEpoch/iteration with minimum mean categorical cross entropy loss.<br>","metadata":{}},{"cell_type":"code","source":"if (n < N_training) {\n#######################\n# SGD and Mini Batch Gradient Descent\n#######################\n  # SGD and Mini Batch Gradient Descent\n  Iteration_lowest_CCEntropy_Loss <- which.min(CCEntropy_Loss$CCEL_testing_x_out)\n  Epoch_lowest_CCEntropy_Loss <- CCEntropy_Loss$epoch[Iteration_lowest_CCEntropy_Loss]\n\n  # Min Testing CCE Loss\n  Min_CCEntropy_Loss <- min(CCEntropy_Loss$CCEL_testing_x_out)\n\n  # Training CCE Loss based on the epoch with the lowest testing CCE Loss\n  Min_CCEntropy_Loss_training <- CCEntropy_Loss$CCEL_x_out[Iteration_lowest_CCEntropy_Loss]\n\n} else {\n#######################\n#Batch Gradient Descent\n#######################\n  # Batch Gradient Descent\n  Epoch_lowest_CCEntropy_Loss <- which.min(CCEntropy_Loss$CCEL_testing_x_out)\n\n  # Min Testing CCE Loss\n  Min_CCEntropy_Loss <- min(CCEntropy_Loss$CCEL_testing_x_out)\n\n  # Training CCE Loss based on the epoch with the lowest testing CCE Loss\n  Min_CCEntropy_Loss_training <- CCEntropy_Loss$CCEL_x_out[Epoch_lowest_CCEntropy_Loss]\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:31:14.165749Z","iopub.execute_input":"2024-02-28T14:31:14.167556Z","iopub.status.idle":"2024-02-28T14:31:14.181525Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Plot Mean CCE Loss and Accuracy\n### Plot Categorical Cross Entropy Testing Loss\nPlot of the mean categorical cross entropy TESTING loss for CCEL_testing_x3<br>\nfor each epoch in log scale. The red point \"CCEL_testing\" is the location<br>\nof the testing loss where the testing loss is the lowest.<br>","metadata":{}},{"cell_type":"code","source":"CCEntropy_Loss_CCEL_testing_x_out <- ggplot(data = CCEntropy_Loss, aes(x = epoch, y = CCEL_testing_x_out)) +\n  geom_line(color = \"darkgreen\") +\n  geom_point(data = subset(CCEntropy_Loss, epoch == Epoch_lowest_CCEntropy_Loss), aes(x = epoch, y = CCEL_testing_x_out), color = \"red\", size = 4) +\n  geom_text(data = subset(CCEntropy_Loss, epoch == Epoch_lowest_CCEntropy_Loss), aes(x = epoch, y = CCEL_testing_x_out, label = \"CCEL_testing\"), vjust = -1) +\n  scale_y_log10() +\n  labs(x = \"Epoch\", y = \"Categorical Cross Entropy Testing Loss\", title = \"Categorical Cross Entropy Testing Loss\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:31:17.876165Z","iopub.execute_input":"2024-02-28T14:31:17.878136Z","iopub.status.idle":"2024-02-28T14:31:17.936176Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 20)\nprint(CCEntropy_Loss_CCEL_testing_x_out)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:31:21.338795Z","iopub.execute_input":"2024-02-28T14:31:21.340558Z","iopub.status.idle":"2024-02-28T14:31:22.079588Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Plot Categorical Cross Entropy Training Loss\nPlot of the mean categorical cross entropy TRAINING loss for CCEL_x3 for<br>\neach epoch in log scale. The red point \"CCEL_training\" is the location of<br>\nthe training loss where the testing loss is the lowest.<br>","metadata":{}},{"cell_type":"code","source":"CCEntropy_Loss_CCEL_x_out <- ggplot(data = CCEntropy_Loss, aes(x = epoch, y = CCEL_x_out)) +\n  geom_line(color = \"darkgreen\") +\n  geom_point(data = subset(CCEntropy_Loss, epoch == Epoch_lowest_CCEntropy_Loss), aes(x = epoch, y = CCEL_x_out), color = \"red\", size = 4) +\n  geom_text(data = subset(CCEntropy_Loss, epoch == Epoch_lowest_CCEntropy_Loss), aes(x = epoch, y = CCEL_x_out, label = \"CCEL_training\"), vjust = -1) +\n  scale_y_log10() +\n  labs(x = \"Epoch\", y = \"Categorical Cross Entropy Training Loss\", title = \"Categorical Cross Entropy Training Loss\") +\n  theme_bw() +\n  theme(plot.title = element_text(hjust = 0.5))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:31:27.399665Z","iopub.execute_input":"2024-02-28T14:31:27.401621Z","iopub.status.idle":"2024-02-28T14:31:27.43239Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 20)\nprint(CCEntropy_Loss_CCEL_x_out)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:31:29.908203Z","iopub.execute_input":"2024-02-28T14:31:29.91094Z","iopub.status.idle":"2024-02-28T14:31:30.932543Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Plot Tracking Model Performance: Training vs Testing Accuracy\nPercent Accuracy Derived from Lowest Loss in Testing Data.<br>","metadata":{}},{"cell_type":"code","source":"\nif (n < N_training) {\n#######################\n# SGD and Mini Batch Gradient Descent\n#######################\nOptimal_Training_Accuracy <-Accuracy_Percent$Training_percent[Iteration_lowest_CCEntropy_Loss]\nOptimal_Testing_Accuracy <-Accuracy_Percent$Testing_percent[Iteration_lowest_CCEntropy_Loss]\n\n} else {\n#######################\n#Batch Gradient Descent\n#######################\nOptimal_Training_Accuracy <-Accuracy_Percent$Training_percent[Epoch_lowest_CCEntropy_Loss]\nOptimal_Testing_Accuracy <-Accuracy_Percent$Testing_percent[Epoch_lowest_CCEntropy_Loss]\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:31:36.396877Z","iopub.execute_input":"2024-02-28T14:31:36.398854Z","iopub.status.idle":"2024-02-28T14:31:36.416038Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Black dot is the accuracy that corresponds to the lowest loss in the<br>\ntesting data.<br>","metadata":{}},{"cell_type":"code","source":"if (n < N_training) {\n  # SGD and Mini Batch Gradient Descent\n  Percent_Accuracy_Plot <- ggplot(Accuracy_Percent, aes(x = seq_len(nrow(Accuracy_Percent)))) +\n      geom_line(aes(y = Testing_percent, color = \"Testing Accuracy\")) +\n      geom_point(aes(x = Iteration_lowest_CCEntropy_Loss, y = Optimal_Testing_Accuracy), color = \"black\", size = 5) +\n      geom_text(aes(x = Iteration_lowest_CCEntropy_Loss - 3, y = Optimal_Testing_Accuracy, label = \"Optimal Testing Accuracy\"), vjust = -1.5) +\n      geom_text(aes(x = Iteration_lowest_CCEntropy_Loss, y = Optimal_Testing_Accuracy, label = as.character(Optimal_Testing_Accuracy)), vjust = 2.5)+\n      labs(x = \"Iteration\", y = \"Accuracy %\", \n        title = \"Testing Accuracy Over Iterations\",\n        color = \"Accuracy Type\") +\n      theme_minimal() +\n      scale_color_manual(values = c(\"blue\", \"black\"), \n             labels = c(\"Testing Accuracy\", \"Optimal Accuracy\")) +\n      scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 2.5))\n\n} else {\n  # Batch Gradient Descent\n  Percent_Accuracy_Plot <- ggplot(Accuracy_Percent, aes(x = seq_len(nrow(Accuracy_Percent)))) +\n    geom_line(aes(y = Testing_percent, color = \"Testing Accuracy\")) +\n    geom_point(aes(x = Epoch_lowest_CCEntropy_Loss, y = Optimal_Testing_Accuracy), color = \"black\", size = 5) +\n    geom_text(aes(x = Epoch_lowest_CCEntropy_Loss - 3, y = Optimal_Testing_Accuracy, label = \"Optimal Testing Accuracy\"), vjust = -1.5) +\n    geom_text(aes(x = Epoch_lowest_CCEntropy_Loss, y = Optimal_Testing_Accuracy, label = as.character(Optimal_Testing_Accuracy)), vjust = 2.5)+\n    labs(x = \"Epoch\", y = \"Accuracy %\", \n         title = \"Testing Accuracy Over Epochs\",\n         color = \"Accuracy Type\") +\n    theme_minimal() +\n    scale_color_manual(values = c(\"blue\", \"black\"), \n                       labels = c(\"Testing Accuracy\", \"Optimal Accuracy\")) +\n    scale_y_continuous(limits = c(0, 100), breaks = seq(0, 100, by = 2.5))\n}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:31:39.21971Z","iopub.execute_input":"2024-02-28T14:31:39.221695Z","iopub.status.idle":"2024-02-28T14:31:39.262661Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"options(repr.plot.width = 20, repr.plot.height = 20)\nprint(Percent_Accuracy_Plot)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:31:42.362037Z","iopub.execute_input":"2024-02-28T14:31:42.363829Z","iopub.status.idle":"2024-02-28T14:31:43.128256Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Neural Network Performance Summary\n### No Mapping vs Mapping","metadata":{}},{"cell_type":"code","source":"# No mapping vs Fourier Feature Mapping\nswitch(NoMapping_vs_FourierFeatureMapping,\n       \"No mapping\" = {\nprint(paste(\"No mapping\"))\n       },\n       \"Feature Mapping\" = {\nprint(paste(\"Fourier Feature Mapping\"))\n       })  ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:31:51.105381Z","iopub.execute_input":"2024-02-28T14:31:51.107257Z","iopub.status.idle":"2024-02-28T14:31:51.1264Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Neural Network Parameters","metadata":{}},{"cell_type":"code","source":"if (n < N_training) {\n#SGD and Mini Batch Gradient Descent\nprint(paste(\"Number of training observations used in each batch:\",n))\n} else {\n#Batch Gradient Descent\nprint(paste(\"Number of training observations used in each batch:\",\"All observations\"))\n} \n\nprint(paste(\"Number of hidden layers:\",num_hidden_layers)) \n\nif (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\nprint(paste(\"Number of neurons in hidden layer:\",nu))\n} else {\n###############\n# When using Two Hidden Layers\n###############\nprint(paste(\"Number of neurons in hidden layer 1:\",nu))\nprint(paste(\"Number of neurons in hidden layer 2:\",nu2))\n} ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:31:53.571433Z","iopub.execute_input":"2024-02-28T14:31:53.573478Z","iopub.status.idle":"2024-02-28T14:31:53.605115Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Epoch with Min Testing CCE Loss","metadata":{}},{"cell_type":"code","source":"print(paste(\"Epoch with Minimum Testing CCE Loss:\", Epoch_lowest_CCEntropy_Loss))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:31:57.725462Z","iopub.execute_input":"2024-02-28T14:31:57.734721Z","iopub.status.idle":"2024-02-28T14:31:57.751204Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Categorical Cross Entropy Loss","metadata":{}},{"cell_type":"code","source":"print(paste(\"Minimum Testing CCE Loss:\", Min_CCEntropy_Loss))\nprint(paste(\"Training CCE Loss based on lowest testing CCE Loss:\", Min_CCEntropy_Loss_training)) ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:32:11.324419Z","iopub.execute_input":"2024-02-28T14:32:11.327288Z","iopub.status.idle":"2024-02-28T14:32:11.352037Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Optimal Accuracy","metadata":{}},{"cell_type":"code","source":"print(paste(\"Optimal Testing Accuracy %:\", Optimal_Testing_Accuracy)) ","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:34:36.856605Z","iopub.execute_input":"2024-02-28T14:34:36.859449Z","iopub.status.idle":"2024-02-28T14:34:36.899073Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Feedforward Prediction\n### Optimal M Weight Matrices","metadata":{}},{"cell_type":"code","source":"###########################\n# Optimal M Weight Matrices\n###########################\nif (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\nif (n < N_training) {\n#SGD and Mini Batch Gradient Descent\nM1_min <-M1_list[[Iteration_lowest_CCEntropy_Loss]]\n\nM2_min <-M2_list[[Iteration_lowest_CCEntropy_Loss]]\n} else {\n#Batch Gradient Descent\nM1_min <-M1_list[[Epoch_lowest_CCEntropy_Loss]]\n\nM2_min <-M2_list[[Epoch_lowest_CCEntropy_Loss]]\n}\n\n} else {\n###############\n# When using Two Hidden Layers\n###############\nif (n < N_training) {\n#SGD and Mini Batch Gradient Descent\nM1_min <-M1_list[[Iteration_lowest_CCEntropy_Loss]]\n\nM2_min <-M2_list[[Iteration_lowest_CCEntropy_Loss]]\n\nM3_min <-M3_list[[Iteration_lowest_CCEntropy_Loss]]\n} else {\n#Batch Gradient Descent\nM1_min <-M1_list[[Epoch_lowest_CCEntropy_Loss]]\n\nM2_min <-M2_list[[Epoch_lowest_CCEntropy_Loss]]\n\nM3_min <-M3_list[[Epoch_lowest_CCEntropy_Loss]]\n}\n\n}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:32:18.319165Z","iopub.execute_input":"2024-02-28T14:32:18.321064Z","iopub.status.idle":"2024-02-28T14:32:18.336465Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Feedforward Code","metadata":{}},{"cell_type":"code","source":"# Randomly select 3 images from the testing data\nRandomly_selected_rows_pred <-sample(nrow(Data_testing_scaled), n_prediction, replace = FALSE)\n\nData_pred <-Data_testing_scaled[Randomly_selected_rows_pred, ] \n\nRow_Image_Matrix_pred <-Data_pred[, 2:ncol(Data_pred)]  %>%  as.matrix()\n  ###############################################\n  # Code for Training forward forward pass\n  ###############################################\n#########################\n# No mapping vs Fourier Feature Mapping\nswitch(NoMapping_vs_FourierFeatureMapping,\n       \"No mapping\" = {\nX1_pred <-Row_Image_Matrix_pred %>% t()\n\nX1_map_vs_no_map_pred <-X1_pred\n       },\n       \"Feature Mapping\" = {\n#Xi = X1_pred\n           \nX1_pred <-Row_Image_Matrix_pred %>% t()\n\nHf_pi_B_Xi_pred <-Hf_pi_B_pred * X1_pred\n\n# apply the cos to each element of the matrix\ncos_element_wise_pred <-cos(Hf_pi_B_Xi_pred)\n\n# apply the sin to each element of the matrix\nsin_element_wise_pred <-sin(Hf_pi_B_Xi_pred)\n\n###############################################\n# Create a vector of alternating ones and zeros\none_zero_V_pred <- t(rep(c(1, 0), length.out = Xd_m_rows))  %>% as.matrix() \n\n# Repeat and bind the vector into a matrix\none_zero_M_pred <- matrix(rep(one_zero_V_pred, n_prediction,), nrow = Xd_m_rows, ncol = n_prediction, byrow = FALSE)  \n\ncos_matrix_pred <-one_zero_M_pred * cos_element_wise_pred\n\n# Create a vector of alternating zeros and ones\nzero_one_V_pred <- t(rep(c(0, 1), length.out = Xd_m_rows))  %>% as.matrix()\n\n# Repeat and bind the vector into a matrix\nzero_one_M_pred <- matrix(rep(zero_one_V_pred, n_prediction,), nrow = Xd_m_rows, ncol = n_prediction, byrow = FALSE)\n\nsin_matrix_pred <-zero_one_M_pred * sin_element_wise_pred\n\n# Fourier Feature Mapping\ngamma_Xi_pred <- cos_matrix_pred + sin_matrix_pred\n\nX1_map_vs_no_map_pred <-gamma_Xi_pred\n       })\n#########################\nX1_pred <-rbind(X1_map_vs_no_map_pred, rep(1, ncol(X1_map_vs_no_map_pred)))\n\nZ2_pred <- M1_min %*% X1_pred\n\nLeakyReLU_pred <- t(apply(Z2_pred, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n    as.matrix()\n\nX2_pred <- rbind(LeakyReLU_pred, 1) %>% \n  as.matrix()\n###############################################\n# For one and two hidden layers\nif (num_hidden_layers < 2) {\n###############\n# When using One Hidden Layer\n###############\nZ_out_pred <- M2_min %*% X2_pred\n\n} else {\n###############\n# When using Two Hidden Layers\n###############\nZ3_pred <- M2_min %*% X2_pred\n\nLeakyReLU2_pred <- t(apply(Z3_pred, 1, function(x) ifelse(x >= 0, x, LeakyReLU_alpha * x))) %>% \n    as.matrix()\n\nX3_pred <- rbind(LeakyReLU2_pred, 1) %>% \n  as.matrix()\n\nZ_out_pred <- M3_min %*% X3_pred\n}\n\nX_out_pred <-apply(Z_out_pred, 2, softmax_MAX)\n\n# Predicted Minist Digit\nMnist_digit_pred <-apply(X_out_pred, 2, which.max)-1","metadata":{"execution":{"iopub.status.busy":"2024-02-28T14:33:48.223416Z","iopub.execute_input":"2024-02-28T14:33:48.225263Z","iopub.status.idle":"2024-02-28T14:33:48.273939Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Pick 3 Random Images From Testing Data to Predict.","metadata":{}},{"cell_type":"code","source":"# Each row vector in Row_Image_Matrix_pred is a 784 pixel image. sqrt(784) = 28\n# Thus reshape each row vector into a 28 x 28 matrix\n# Max pixel value comes from the max value in the original data \n\n# Define the show_digit function\nshow_digit <- function(arr784, col = gray.colors(max(arr784))) {\n  image(matrix(arr784, nrow = 28)[, 28:1], col = col)\n}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:33:52.784047Z","iopub.execute_input":"2024-02-28T14:33:52.786203Z","iopub.status.idle":"2024-02-28T14:33:52.805789Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape the first row vector into a 28 x 28 matrix\nfirst_digit_matrix <- Row_Image_Matrix_pred[1, ] %>% matrix(nrow = 28, ncol = 28, byrow = FALSE)\n\n# Plot the first digit matrix and print the prediction\nprint(paste(\"Predicted Number:\",Mnist_digit_pred[1]))\nprint(paste(\"Image:\"))\nshow_digit(first_digit_matrix)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:33:55.597671Z","iopub.execute_input":"2024-02-28T14:33:55.602468Z","iopub.status.idle":"2024-02-28T14:33:56.004416Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape the second row vector into a 28 x 28 matrix\nsecond_digit_matrix <- Row_Image_Matrix_pred[2, ] %>% matrix(nrow = 28, ncol = 28, byrow = FALSE)\n\n# Plot the second digit matrix and print the prediction\nprint(paste(\"Predicted Number:\",Mnist_digit_pred[2]))\nprint(paste(\"Image:\"))\nshow_digit(second_digit_matrix)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:34:01.498093Z","iopub.execute_input":"2024-02-28T14:34:01.500055Z","iopub.status.idle":"2024-02-28T14:34:01.904507Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Reshape the third row vector into a 28 x 28 matrix\nthird_digit_matrix <- Row_Image_Matrix_pred[3, ] %>% matrix(nrow = 28, ncol = 28, byrow = FALSE)\n\n# Plot the third digit matrix and print the prediction\nprint(paste(\"Predicted Number:\",Mnist_digit_pred[3]))\nprint(paste(\"Image:\"))\nshow_digit(third_digit_matrix)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-02-28T14:34:05.690641Z","iopub.execute_input":"2024-02-28T14:34:05.692486Z","iopub.status.idle":"2024-02-28T14:34:06.082647Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**FIN**","metadata":{}},{"cell_type":"markdown","source":"## References\n\nB, U. (2021, November 15). Cost Function in Machine Learning. Medium.<br>\n  https://medium.com/@uma.bollikonda/cost-function-in-machine-learning-129de85120d5<br>\n\n@article{Chadha2020DistilledNeuralNetworks,<br>\n  title   = {Neural Networks},<br>\n  author  = {Chadha, Aman},<br>\n  journal = {Distilled Notes for Stanford CS229: Machine Learning},<br>\n  year    = {2020},<br>\n  note    = {\\url{https://aman.ai}}<br>\n}<br>\n\ncharleshsliao. (2017, February 25). Two Ways of Visualization of MNIST with R. Charles’ Hodgepodge.<br>\nhttps://charleshsliao.wordpress.com/2017/02/25/two-ways-of-visualization-of-mnist-with-r/<br>\n\nKingma, D., & Lei Ba, J. (2017). ADAM: A METHOD FOR STOCHASTIC OPTIMIZATION.<br>\n  https://arxiv.org/pdf/1412.6980.pdf<br>\n\nLeCun, Y. (2009). MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges. Lecun.com.<br>\n  http://yann.lecun.com/exdb/mnist/<br>\n\nMildenhall, B. (n.d.). Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains (10min talk)<br> \n  [Review of Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains (10min talk)].<br>\n  https://www.youtube.com/watch?v=iKyIJ_EtSkw&ab_channel=BENMILDENHALL<br>\n\nneuralthreads. (2021, December 6). Softmax function — It is frustrating that everyone talks about it but very few talk about its….<br> \nMedium. https://neuralthreads.medium.com/softmax-function-it-is-frustrating-that-everyone-talks-about-it-but-very-few-talk-about-its-54c90b9d0acd<br>\n\nSagar, A. (n.d.). 5 Techniques to Prevent Overfitting in Neural Networks<br>\n  [Review of 5 Techniques to Prevent Overfitting in Neural Networks]. KDnuggets.<br> \n  https://www.kdnuggets.com/2019/12/5-techniques-prevent-overfitting-neural-networks.html<br>\n\nTaboga, M. (n.d.). Vec operator [Review of Vec operator]. StatLect.<br>\n  https://www.statlect.com/matrix-algebra/vec-operator<br>\n\nTancik, M., Srinivasan, P. P., Mildenhall, B., Fridovich-Keil, S., Raghavan, N., Singhal, U.,<br>\n  Ramamoorthi, R., Barron, J. T., &amp; Ng, R. (2020, June 18).<br>\n  Fourier features let networks learn high frequency functions in low dimensional domains.<br> \n  arXiv.org. https://arxiv.org/abs/2006.10739<br>\n","metadata":{}}]}